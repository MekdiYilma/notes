{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced SQL\n",
    "\n",
    "## Success Criteria \n",
    "\n",
    "Today I will feel successful if I can...\n",
    "\n",
    "- Connect to a database from within a python program and run queries\n",
    "- Understand psycopg2's cursors and commits\n",
    "- Explain SQL Injection and when it can occur \n",
    "- Generate dynamic queries\n",
    "- Explain the concept Database Normalization\n",
    "- Feel comfortable with the following concepts: Primary keys, foriegn keys, and the ERD\n",
    "\n",
    "\n",
    "## Agenda\n",
    "Part 1: Work with Combining SQl and Python\n",
    "- use psycopg2 library \n",
    "- create connections to our databases stored in our docker container\n",
    "- visualize outputs of our SQL queries\n",
    "\n",
    "Part 2: RDBMS the why and how\n",
    "- Reintroduce RDBMS\n",
    "- Note aspects of the structure\n",
    "- Go through Database Normalization\n",
    "- Order of Operations for SQL\n",
    "- Converse about query execution plan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 Combining SQL and Python\n",
    "\n",
    "Often you will find yourself working with data that are only accessable through SQL.  However, your machine-learning capabilities are built in Python.  To resolve this issue, we can simply set up a connection from Python to the SQL database to bring the data to us."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why do we care?\n",
    "\n",
    "- SQL-based databases are extremely common in almost all industry environments\n",
    "- Can leverage the benefit of SQL's structure and scalability, while maintaining the flexibility of Python\n",
    "- Very useful for scaled data pipelines, pre-cleaning, data exploration\n",
    "- Allows for dynamic query generation and hence automations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## psycopg2\n",
    "\n",
    "- A Python library that allows for connections with PostgresSQL databases to easily query and retrieve data for analysis.\n",
    "- [Documentation--Includes Installation Instructions](http://initd.org/psycopg/docs/install.html)\n",
    "- In addition to what's listed in the documentation, if you have the anaconda distribution of Python \n",
    "- There are similar packages for other flavors of SQL that work much the same way\n",
    "\n",
    "To install using anaconda try \\\n",
    "`conda update all`\\\n",
    "`conda install psycopg2`\\\n",
    "If that does not work for your environment try:\\\n",
    "`pip install psycopg2-binary`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Workflow\n",
    "\n",
    "1. Establish connection to Postgres database using psycopg2\n",
    "2. Create a cursor\n",
    "3. Use the cursor to execute SQL queries and retrieve data\n",
    "4. Commit SQL actions\n",
    "4. Close the cursor and connection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Walkthrough 1: Creating a database from Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#before starting with this notebook, make sure you set your docker path. If running this locally, just use your local path.\n",
    "\n",
    "#/home/data (from docker run command)\n",
    "# Galvanize/lectures/sql-advanced' is the remaining path for me personally to get to this lecture material \n",
    "#your path is based on where you started your container and your computer file structures \n",
    "docker_path = '/home/data/Desktop/dsi/notes/sql-advance'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mimg\u001b[m\u001b[m/                        psycopg2_exercise.ipynb\r\n",
      "\u001b[34mlogins_data\u001b[m\u001b[m/                sql-advanced-lecture.ipynb\r\n",
      "playgolf.csv\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to the database\n",
    "- Connections must be established using an existing database, username, database IP/URL, and maybe passwords\n",
    "- If you need to create a database, you can first connect to Postgres using the dbname 'postgres' to initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-01-12T08:58:08.165520",
     "start_time": "2017-01-12T08:58:08.091308"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "\n",
    "#first thing we need to do is establish a connection to our database\n",
    "# remember our docker contianer info...\n",
    "# docker run --name pgserv -d -p 5432:5432 -v \"$PWD\":/home/data -e POSTGRES_PASSWORD='galvanize' skylarenglish/galvanize:galv_db\n",
    "conn = psycopg2.connect(dbname='dvdrental', \\\n",
    "                        host='localhost', \\\n",
    "                        port = 5432, \\\n",
    "                        user=\"postgres\", \\\n",
    "                        password=\"galvanize\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "psycopg2.extensions.connection"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate the Cursor\n",
    "\n",
    "- A cursor is a control structure that enables traversal over the records in a database\n",
    "- Executes and fetches data\n",
    "- When the cursor points at the resulting output of a query, it can only read each observation once.  If you choose to see a previously read observation, you must rerun the query. \n",
    "- Can be closed without closing the connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-01-12T08:58:08.185336",
     "start_time": "2017-01-12T08:58:08.167694"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take a look at dvdrentals really quick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''\n",
    "        SELECT \n",
    "            first_name,\n",
    "            last_name, \n",
    "            email\n",
    "        FROM customer\n",
    "        LIMIT 10;\n",
    "        '''\n",
    "cur.execute(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Jared', 'Ely', 'jared.ely@sakilacustomer.org'),\n",
       " ('Mary', 'Smith', 'mary.smith@sakilacustomer.org'),\n",
       " ('Patricia', 'Johnson', 'patricia.johnson@sakilacustomer.org'),\n",
       " ('Linda', 'Williams', 'linda.williams@sakilacustomer.org'),\n",
       " ('Barbara', 'Jones', 'barbara.jones@sakilacustomer.org'),\n",
       " ('Elizabeth', 'Brown', 'elizabeth.brown@sakilacustomer.org'),\n",
       " ('Jennifer', 'Davis', 'jennifer.davis@sakilacustomer.org'),\n",
       " ('Maria', 'Miller', 'maria.miller@sakilacustomer.org'),\n",
       " ('Susan', 'Wilson', 'susan.wilson@sakilacustomer.org'),\n",
       " ('Margaret', 'Moore', 'margaret.moore@sakilacustomer.org')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#I can't view them again until I rerun the querry.... resetting the cursor \n",
    "cur.fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Disconnect from the cursor and database\n",
    "- Cursors and Connections must be closed using .close() or else Postgres will lock certain operation on the database/tables to connection is severed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.close() # This is optional\n",
    "conn.close() # Closing the connection also closes all cursors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Create a database\n",
    "- If you need to create a database first instead of checking out an already existing one, you can first connect to Postgres using the dbname 'postgres' to initialize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(dbname='postgres', \\\n",
    "                        host='localhost', \\\n",
    "                        port = 5432, \\\n",
    "                        user=\"postgres\", \\\n",
    "                        password=\"galvanize\")\n",
    "\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Commits\n",
    "\n",
    "- Data changes are not actually stored until you choose to commit\n",
    "- You can choose to have automatic commit by using ` autocommit = True`\n",
    "- When connecting directly to the Postgres Server to initiate server level commands such as creating a database, you must use the `autocommit = True` option since Postgres does not have \"temporary\" transactions at the database level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.autocommit = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-01-12T08:58:08.896355",
     "start_time": "2017-01-12T08:58:08.204962"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#creating a new Database! notice we want to avoid errors so we drop it first if we accidentally already ran this cell\n",
    "\n",
    "cur.execute('DROP DATABASE IF EXISTS temp;')\n",
    "cur.execute('CREATE DATABASE temp;')\n",
    "#temp database is created but is empty.\n",
    "#if you check DBeaver it will be there! kidna cool huh?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#right now our connection is to \"postgres\" to create this database \n",
    "#close the connection and let's connect to \"temp\"\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Walkthrough 2: Using the new database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to our database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<connection object at 0x7fb10049e470; dsn: 'user=postgres password=xxx dbname=postgres host=localhost port=5432', closed: 1>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-01-12T08:58:08.974359",
     "start_time": "2017-01-12T08:58:08.921473"
    }
   },
   "outputs": [],
   "source": [
    "# This time we are connecting to our new database \"temp\"\n",
    "\n",
    "conn = psycopg2.connect(dbname='temp', host='localhost', port = 5432, user=\"postgres\", password=\"galvanize\")\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-01-12T08:58:08.996294",
     "start_time": "2017-01-12T08:58:08.976269"
    }
   },
   "outputs": [],
   "source": [
    "def connect_to_db(dbname, host, port, user, password=None):\n",
    "    conn = psycopg2.connect(dbname = dbname, host = host, port = port, user = user, password = password)\n",
    "    cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a new table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-01-12T08:58:09.021315",
     "start_time": "2017-01-12T08:58:08.998262"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#make a table full of longin data... \n",
    "#Setting each column to the correct datatype! \n",
    "# why do we need to set this up? (what kind of data are we going to populate with this table?)\n",
    "query = '''\n",
    "        CREATE TABLE logins (\n",
    "            userid integer, \n",
    "            tmstmp timestamp, \n",
    "            type varchar(10)\n",
    "        );\n",
    "        '''\n",
    "cur.execute(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insert data into new table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-01-12T08:58:09.189981",
     "start_time": "2017-01-12T08:58:09.101617"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        COPY logins \n",
      "        FROM '/home/data/Desktop/dsi/notes/sql-advance/logins_data/logins01.csv' \n",
      "        DELIMITER ',' \n",
      "        CSV;\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "# we added csv data into our new table called logins and now we should be able to take a peek \n",
    "query = f'''\n",
    "        COPY logins \n",
    "        FROM '{docker_path}/logins_data/logins01.csv' \n",
    "        DELIMITER ',' \n",
    "        CSV;\n",
    "        '''\n",
    "print(query)\n",
    "cur.execute(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run a query to get 30 records from our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-01-12T08:58:09.226774",
     "start_time": "2017-01-12T08:58:09.192623"
    }
   },
   "outputs": [],
   "source": [
    "query = '''\n",
    "        SELECT *\n",
    "        FROM logins\n",
    "        LIMIT 30;\n",
    "        '''\n",
    "cur.execute(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets look at our data one line at a time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-01-12T08:58:09.259809",
     "start_time": "2017-01-12T08:58:09.230102"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(579, datetime.datetime(2013, 11, 20, 3, 20, 6), 'mobile')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#How do I look at one of the records? \n",
    "cur.fetchone()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Many lines at a time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-01-12T08:58:09.281025",
     "start_time": "2017-01-12T08:58:09.261857"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(823, datetime.datetime(2013, 11, 20, 3, 20, 49), 'web'),\n",
       " (953, datetime.datetime(2013, 11, 20, 3, 28, 49), 'web'),\n",
       " (612, datetime.datetime(2013, 11, 20, 3, 36, 55), 'web'),\n",
       " (269, datetime.datetime(2013, 11, 20, 3, 43, 13), 'web'),\n",
       " (799, datetime.datetime(2013, 11, 20, 3, 56, 55), 'web'),\n",
       " (890, datetime.datetime(2013, 11, 20, 4, 2, 33), 'mobile'),\n",
       " (330, datetime.datetime(2013, 11, 20, 4, 54, 59), 'mobile'),\n",
       " (628, datetime.datetime(2013, 11, 20, 4, 57, 22), 'mobile'),\n",
       " (398, datetime.datetime(2013, 11, 20, 5, 3, 19), 'mobile'),\n",
       " (482, datetime.datetime(2013, 11, 20, 5, 4, 43), 'mobile')]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fetchmany(n) to get n rows (notice we don't get the first one anymore )\n",
    "cur.fetchmany(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skip some lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.scroll(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Or everything at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-01-12T08:58:09.308550",
     "start_time": "2017-01-12T08:58:09.284019"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(274, datetime.datetime(2013, 11, 20, 5, 43, 8), 'mobile'),\n",
       " (581, datetime.datetime(2013, 11, 20, 5, 47, 10), 'web'),\n",
       " (417, datetime.datetime(2013, 11, 20, 5, 54, 37), 'mobile'),\n",
       " (185, datetime.datetime(2013, 11, 20, 5, 56, 22), 'mobile'),\n",
       " (371, datetime.datetime(2013, 11, 20, 5, 58, 35), 'mobile'),\n",
       " (133, datetime.datetime(2013, 11, 20, 5, 59, 7), 'web'),\n",
       " (621, datetime.datetime(2013, 11, 20, 6, 1, 46), 'web'),\n",
       " (306, datetime.datetime(2013, 11, 20, 6, 3, 23), 'mobile'),\n",
       " (509, datetime.datetime(2013, 11, 20, 6, 4, 43), 'web'),\n",
       " (505, datetime.datetime(2013, 11, 20, 6, 9, 52), 'web'),\n",
       " (678, datetime.datetime(2013, 11, 20, 6, 34, 18), 'web'),\n",
       " (889, datetime.datetime(2013, 11, 20, 6, 36, 32), 'mobile'),\n",
       " (202, datetime.datetime(2013, 11, 20, 6, 43, 33), 'mobile'),\n",
       " (614, datetime.datetime(2013, 11, 20, 6, 47, 55), 'mobile'),\n",
       " (882, datetime.datetime(2013, 11, 20, 6, 49), 'mobile')]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#How do I grab all remaining rows at least? (set to varibale results)\n",
    "cur.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = list(cur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(579, datetime.datetime(2013, 11, 20, 3, 20, 6), 'mobile'),\n",
       " (823, datetime.datetime(2013, 11, 20, 3, 20, 49), 'web'),\n",
       " (953, datetime.datetime(2013, 11, 20, 3, 28, 49), 'web'),\n",
       " (612, datetime.datetime(2013, 11, 20, 3, 36, 55), 'web'),\n",
       " (269, datetime.datetime(2013, 11, 20, 3, 43, 13), 'web'),\n",
       " (799, datetime.datetime(2013, 11, 20, 3, 56, 55), 'web'),\n",
       " (890, datetime.datetime(2013, 11, 20, 4, 2, 33), 'mobile'),\n",
       " (330, datetime.datetime(2013, 11, 20, 4, 54, 59), 'mobile'),\n",
       " (628, datetime.datetime(2013, 11, 20, 4, 57, 22), 'mobile'),\n",
       " (398, datetime.datetime(2013, 11, 20, 5, 3, 19), 'mobile'),\n",
       " (482, datetime.datetime(2013, 11, 20, 5, 4, 43), 'mobile'),\n",
       " (581, datetime.datetime(2013, 11, 20, 5, 12, 3), 'mobile'),\n",
       " (370, datetime.datetime(2013, 11, 20, 5, 26, 46), 'mobile'),\n",
       " (230, datetime.datetime(2013, 11, 20, 5, 28, 29), 'web'),\n",
       " (596, datetime.datetime(2013, 11, 20, 5, 28, 36), 'web'),\n",
       " (274, datetime.datetime(2013, 11, 20, 5, 43, 8), 'mobile'),\n",
       " (581, datetime.datetime(2013, 11, 20, 5, 47, 10), 'web'),\n",
       " (417, datetime.datetime(2013, 11, 20, 5, 54, 37), 'mobile'),\n",
       " (185, datetime.datetime(2013, 11, 20, 5, 56, 22), 'mobile'),\n",
       " (371, datetime.datetime(2013, 11, 20, 5, 58, 35), 'mobile'),\n",
       " (133, datetime.datetime(2013, 11, 20, 5, 59, 7), 'web'),\n",
       " (621, datetime.datetime(2013, 11, 20, 6, 1, 46), 'web'),\n",
       " (306, datetime.datetime(2013, 11, 20, 6, 3, 23), 'mobile'),\n",
       " (509, datetime.datetime(2013, 11, 20, 6, 4, 43), 'web'),\n",
       " (505, datetime.datetime(2013, 11, 20, 6, 9, 52), 'web'),\n",
       " (678, datetime.datetime(2013, 11, 20, 6, 34, 18), 'web'),\n",
       " (889, datetime.datetime(2013, 11, 20, 6, 36, 32), 'mobile'),\n",
       " (202, datetime.datetime(2013, 11, 20, 6, 43, 33), 'mobile'),\n",
       " (614, datetime.datetime(2013, 11, 20, 6, 47, 55), 'mobile'),\n",
       " (882, datetime.datetime(2013, 11, 20, 6, 49), 'mobile')]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-01-12T08:58:09.377396",
     "start_time": "2017-01-12T08:58:09.342447"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    }
   ],
   "source": [
    "print(len(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You can even iterate over the cursor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-01-12T08:58:09.417730",
     "start_time": "2017-01-12T08:58:09.380019"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On 2013-11-20 03:20:06: user 2013-11-20 03:20:06 logged in via mobile\n",
      "On 2013-11-20 03:20:49: user 2013-11-20 03:20:49 logged in via web\n",
      "On 2013-11-20 03:28:49: user 2013-11-20 03:28:49 logged in via web\n",
      "On 2013-11-20 03:36:55: user 2013-11-20 03:36:55 logged in via web\n",
      "On 2013-11-20 03:43:13: user 2013-11-20 03:43:13 logged in via web\n",
      "On 2013-11-20 03:56:55: user 2013-11-20 03:56:55 logged in via web\n",
      "On 2013-11-20 04:02:33: user 2013-11-20 04:02:33 logged in via mobile\n",
      "On 2013-11-20 04:54:59: user 2013-11-20 04:54:59 logged in via mobile\n",
      "On 2013-11-20 04:57:22: user 2013-11-20 04:57:22 logged in via mobile\n",
      "On 2013-11-20 05:03:19: user 2013-11-20 05:03:19 logged in via mobile\n",
      "On 2013-11-20 05:04:43: user 2013-11-20 05:04:43 logged in via mobile\n",
      "On 2013-11-20 05:12:03: user 2013-11-20 05:12:03 logged in via mobile\n",
      "On 2013-11-20 05:26:46: user 2013-11-20 05:26:46 logged in via mobile\n",
      "On 2013-11-20 05:28:29: user 2013-11-20 05:28:29 logged in via web\n",
      "On 2013-11-20 05:28:36: user 2013-11-20 05:28:36 logged in via web\n",
      "On 2013-11-20 05:43:08: user 2013-11-20 05:43:08 logged in via mobile\n",
      "On 2013-11-20 05:47:10: user 2013-11-20 05:47:10 logged in via web\n",
      "On 2013-11-20 05:54:37: user 2013-11-20 05:54:37 logged in via mobile\n",
      "On 2013-11-20 05:56:22: user 2013-11-20 05:56:22 logged in via mobile\n",
      "On 2013-11-20 05:58:35: user 2013-11-20 05:58:35 logged in via mobile\n",
      "On 2013-11-20 05:59:07: user 2013-11-20 05:59:07 logged in via web\n",
      "On 2013-11-20 06:01:46: user 2013-11-20 06:01:46 logged in via web\n",
      "On 2013-11-20 06:03:23: user 2013-11-20 06:03:23 logged in via mobile\n",
      "On 2013-11-20 06:04:43: user 2013-11-20 06:04:43 logged in via web\n",
      "On 2013-11-20 06:09:52: user 2013-11-20 06:09:52 logged in via web\n",
      "On 2013-11-20 06:34:18: user 2013-11-20 06:34:18 logged in via web\n",
      "On 2013-11-20 06:36:32: user 2013-11-20 06:36:32 logged in via mobile\n",
      "On 2013-11-20 06:43:33: user 2013-11-20 06:43:33 logged in via mobile\n",
      "On 2013-11-20 06:47:55: user 2013-11-20 06:47:55 logged in via mobile\n",
      "On 2013-11-20 06:49:00: user 2013-11-20 06:49:00 logged in via mobile\n"
     ]
    }
   ],
   "source": [
    "#since we stored our query in a variable, I can re run it easily here\n",
    "cur.execute(query)\n",
    "for record in cur:\n",
    "    print(f\"On {record[1]}: user {record[1]} logged in via {record[2]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dynamic Queries\n",
    "\n",
    "- A Dynamic Query is a query that generates based on context.\n",
    "\n",
    "- Sometimes, the SQL string needs to be constructed dynamically, given some input parameters.... but be careful! We will discuss the dangers of SQL injection! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example\n",
    "\n",
    "We have 8 login csv files that we need to insert into the logins table.  Instead of doing a COPY FROM query 8 times, we should utilize Python (or any future languages) to make this more efficient. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First lets get an idea of how many records we start with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-01-12T08:58:09.446430",
     "start_time": "2017-01-12T08:58:09.421547"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "cur.execute('SELECT count(*) FROM logins;')\n",
    "record_count = cur.fetchone()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-01-12T08:58:09.471580",
     "start_time": "2017-01-12T08:58:09.451032"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9999, 3)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "logins01 = pd.read_csv('logins_data/logins01.csv')\n",
    "logins01.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-01-12T08:58:09.515994",
     "start_time": "2017-01-12T08:58:09.476168"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(record_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a query template and determine file path for imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## **[WARNING: BEWARE OF SQL INJECTION](http://initd.org/psycopg/docs/usage.html)**\n",
    "\n",
    "### What is an SQL Injection Attack?\n",
    "\n",
    "from W3schools.com:\n",
    "\n",
    " - SQL injection is a code injection technique that might destroy your database.\n",
    " - SQL injection is **one of the most common** web hacking techniques.\n",
    " - SQL injection is the placement of malicious code in SQL statements, via web page input.\n",
    " \n",
    "SQL injection usually occurs when you ask a user for input, like their username/userid, and instead of a name/id, the user gives you an SQL statement that you will **unknowingly run on your database.**\n",
    "\n",
    "Here is an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-01-12T08:58:09.596979",
     "start_time": "2017-01-12T08:58:09.573540"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT * FROM logins WHERE tmstmp > 2013-10-20; DROP TABLE logins;\n"
     ]
    }
   ],
   "source": [
    "date_cut = \"2013-10-20; DROP TABLE logins\" # The user enters a date in a field on a web form\n",
    "\n",
    "horribly_risky = \"SELECT * FROM logins WHERE tmstmp > %s;\" % date_cut\n",
    "\n",
    "print(horribly_risky)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT * FROM logins WHERE tmstmp > 2013-10-20; DROP TABLE loginss;\n"
     ]
    }
   ],
   "source": [
    "date_cut = \"2013-10-20; DROP TABLE logins\" # The user enters a date in a field on a web form\n",
    "\n",
    "horribly_risky = f\"SELECT * FROM logins WHERE tmstmp > {date_cut}s;\" \n",
    "\n",
    "print(horribly_risky)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To avoid SQL Injections **NEVER** use + or % or .format to reformat strings to be used with .execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-01-12T08:58:09.571188",
     "start_time": "2017-01-12T08:58:09.521349"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT * FROM logins WHERE userid = 579;\n",
      "SELECT * FROM logins WHERE tmstmp > 2013-10-20;\n"
     ]
    }
   ],
   "source": [
    "num = 579\n",
    "terribly_unsafe = \"SELECT * FROM logins WHERE userid = \" + str(num) + \";\"\n",
    "print(terribly_unsafe)\n",
    "\n",
    "\n",
    "date_cut = \"2013-10-20\"\n",
    "horribly_risky = \"SELECT * FROM logins WHERE tmstmp > %s;\" % date_cut\n",
    "print(horribly_risky)\n",
    "## Python is happy, but if num or date_cut included something malicious\n",
    "## your data could be at risk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's write these queries safely\n",
    "\n",
    "The Python string operator % must not be used: the execute() method accepts a tuple or dictionary of values as second parameter. Never use % or + to merge values into queries:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT tmstmp FROM logins WHERE tmstmp > %(date_cut)s ; {'date_cut': '2013-10-20'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(datetime.datetime(2013, 11, 20, 3, 20, 6),),\n",
       " (datetime.datetime(2013, 11, 20, 3, 20, 49),),\n",
       " (datetime.datetime(2013, 11, 20, 3, 28, 49),),\n",
       " (datetime.datetime(2013, 11, 20, 3, 36, 55),),\n",
       " (datetime.datetime(2013, 11, 20, 3, 43, 13),),\n",
       " (datetime.datetime(2013, 11, 20, 3, 56, 55),),\n",
       " (datetime.datetime(2013, 11, 20, 4, 2, 33),),\n",
       " (datetime.datetime(2013, 11, 20, 4, 54, 59),),\n",
       " (datetime.datetime(2013, 11, 20, 4, 57, 22),),\n",
       " (datetime.datetime(2013, 11, 20, 5, 3, 19),)]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_cut = \"2013-10-20; DROP TABLE logins\" # The user enters a date in a field on a web form\n",
    "\n",
    "date_cut2 = \"2013-10-20\"\n",
    "\n",
    "safe_dynamic_query = \"SELECT tmstmp FROM logins WHERE tmstmp > %(date_cut)s ;\" \n",
    "\n",
    "print(safe_dynamic_query, {'date_cut':date_cut2})\n",
    "\n",
    "cur.execute(safe_dynamic_query, {'date_cut':date_cut2})\n",
    "\n",
    "cur.fetchmany(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "To use .execute the corrent way, see how in the query string we used \n",
    "`%(file_path)s`\\\n",
    "Then in the `.execute()` method we used `{'file_path':file_path}` as a parameter\n",
    "\n",
    "\n",
    "#### For more on SQL injections check out [bobby-tables.com](http://www.bobby-tables.com/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now back to our query template and determine file path for imports\n",
    "\n",
    "### Practice safe SQL with Psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-01-12T08:58:09.614272",
     "start_time": "2017-01-12T08:58:09.599957"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "query = '''\n",
    "        COPY logins \n",
    "        FROM %(file_path)s\n",
    "        DELIMITER ','\n",
    "        CSV;\n",
    "        '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mimg\u001b[m\u001b[m/                        psycopg2_exercise.ipynb\r\n",
      "\u001b[34mlogins_data\u001b[m\u001b[m/                sql-advanced-lecture.ipynb\r\n",
      "playgolf.csv\r\n"
     ]
    }
   ],
   "source": [
    "ls "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['logins08.csv',\n",
       " 'logins06.csv',\n",
       " 'logins07.csv',\n",
       " 'logins05.csv',\n",
       " 'logins04.csv',\n",
       " 'logins01.csv',\n",
       " 'logins03.csv',\n",
       " 'logins02.csv']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "\n",
    "folder_path_local = 'logins_data/'\n",
    "\n",
    "os.listdir(folder_path_local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-01-12T08:58:10.030936",
     "start_time": "2017-01-12T08:58:09.615754"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logins08.csv inserted into table.\n",
      "logins06.csv inserted into table.\n",
      "logins07.csv inserted into table.\n",
      "logins05.csv inserted into table.\n",
      "logins04.csv inserted into table.\n",
      "logins03.csv inserted into table.\n",
      "logins02.csv inserted into table.\n"
     ]
    }
   ],
   "source": [
    "# docker_path = '/home/data/Desktop/dsi/notes/sql-advance'\n",
    "\n",
    "\n",
    "folder_path_docker = docker_path + '/logins_data/'\n",
    "# folder_path_local = local_path + '/logins_data/'\n",
    "folder_path_local = 'logins_data/'\n",
    "\n",
    "\n",
    "for file_name in os.listdir(folder_path_local):\n",
    "    if file_name.endswith('.csv') and file_name != 'logins01.csv':\n",
    "        file_path=folder_path_docker+file_name\n",
    "        cur.execute(query, {'file_path':file_path})\n",
    "        print('{0} inserted into table.'.format(file_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, Let's check the total number of records we have right now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-01-12T08:58:10.065091",
     "start_time": "2017-01-12T08:58:10.033034"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old record count: 10000\n",
      "New record count: 78588\n"
     ]
    }
   ],
   "source": [
    "print(\"Old record count: {}\".format(record_count))\n",
    "\n",
    "cur.execute('SELECT count(*) FROM logins;')\n",
    "record_count = cur.fetchone()[0]\n",
    "\n",
    "print(\"New record count: {}\".format(record_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-01-12T08:57:22.334048",
     "start_time": "2017-01-12T08:57:22.321062"
    }
   },
   "source": [
    "### Transactions can be rolled back until they're committed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-01-12T08:58:10.188575",
     "start_time": "2017-01-12T08:58:10.067757"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After rollback: 10000\n"
     ]
    }
   ],
   "source": [
    "conn.rollback()\n",
    "\n",
    "cur.execute('SELECT count(*) FROM logins;')\n",
    "record_count = cur.fetchone()[0]\n",
    "\n",
    "print(\"After rollback: {}\".format(record_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Don't forget to commit your changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-01-12T08:58:10.189096",
     "start_time": "2017-01-12T16:58:08.148Z"
    }
   },
   "outputs": [],
   "source": [
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New record count: 10000\n"
     ]
    }
   ],
   "source": [
    "cur.execute('SELECT count(*) FROM logins;')\n",
    "record_count = cur.fetchone()[0]\n",
    "\n",
    "print(\"New record count: {}\".format(record_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Close your connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-01-12T08:58:10.189407",
     "start_time": "2017-01-12T16:58:08.149Z"
    }
   },
   "outputs": [],
   "source": [
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using python `with` Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-01-12T08:58:10.189716",
     "start_time": "2017-01-12T16:58:08.151Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cursor inside with block: <cursor object at 0x7fb12076a050; closed: 0>\n",
      "10000\n",
      "Cursor outside with block: <cursor object at 0x7fb12076a050; closed: -1>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "query = \"SELECT count(*) FROM logins;\"\n",
    "with psycopg2.connect(dbname='temp', \\\n",
    "                      host='localhost', \\\n",
    "                      port = 5432, \\\n",
    "                      user=\"postgres\", \\\n",
    "                      password=\"galvanize\") as conn:\n",
    "    with conn.cursor() as curs:\n",
    "        print(\"Cursor inside with block: {}\".format(curs))\n",
    "        curs.execute(query)\n",
    "        record_count = curs.fetchone()[0]\n",
    "        print(record_count)\n",
    "    print(\"Cursor outside with block: {}\".format(curs))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-01-12T08:51:21.531861",
     "start_time": "2017-01-12T08:51:21.518559"
    }
   },
   "source": [
    "### Note that the connection is *not* closed automatically:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-01-12T08:58:10.189999",
     "start_time": "2017-01-12T16:58:08.153Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<connection object at 0x7fb100f5f890; dsn: 'user=postgres password=xxx dbname=temp host=localhost port=5432', closed: 0>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-01-12T08:58:10.190294",
     "start_time": "2017-01-12T16:58:08.154Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<connection object at 0x7fb100f5f890; dsn: 'user=postgres password=xxx dbname=temp host=localhost port=5432', closed: 1>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn.close()\n",
    "conn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Things to Remember about psycopg2\n",
    "\n",
    "* Connections must be established using an existing database, username, database IP/URL, and maybe passwords\n",
    "* If you have no created databases, you can connect to Postgres using the dbname 'postgres' to initialize db commands\n",
    "* Data changes are not actually stored until you choose to commit. This can be done either through `conn.commit()` or setting `autocommit = True`.  Until commited, all transactions are only temporary stored.\n",
    "* Autocommit = True is necessary to do database commands like CREATE DATABASE.  This is because Postgres does not have temporary transactions at the database level.\n",
    "* If you ever need to build similar pipelines for other forms of database, there are libraries such PyODBC which operate very similarly.\n",
    "* SQL connection databases utilizes cursors for data traversal and retrieval.  This is kind of like an iterator in Python.\n",
    "* Cursor operations typically goes like the following:\n",
    "    - execute a query\n",
    "    - fetch rows from query result if it is a SELECT query\n",
    "    - because it is iterative, previously fetched rows can only be fetched again by rerunning the query\n",
    "    - close cursor through .close()\n",
    "* Cursors and Connections must be closed using .close() or else Postgres will lock certain operation on the database/tables to connection is severed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 RDBMS the why and how:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relational Database Management System (RDBMS)\n",
    "\n",
    "#### It is a persistent data storage system\n",
    " - Schema defines the structure of a table or a database\n",
    " - Database is composed of a number of user-defined tables\n",
    " - Each table has columns (or fields) and rows (or records)\n",
    " - A column is of a certain data type such as an integer, text, or date\n",
    "\n",
    "With a new data source, your first task is typically to understand the schema. \n",
    "This will likely take time and conversations with those that gave you access to the database or its data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![RDBMS Diagram](img/RDBMS_Diagram.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RDBMS and SQL\n",
    "\n",
    " - SQL is the language used to query relational databases\n",
    " - **All RDBMS** use SQL and the syntax and keywords are the same for the most part, across systems\n",
    " - **SQL is used to interact** with RDBMS, allowing you to create tables, alter tables, insert records, update records, delete records, and query records within and across tables.\n",
    " - Even non-relational databases like **Hadoop** usually have a SQL-like interface available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Database Life Cycle (DBLC)\n",
    "\n",
    "![DBLC](img/DBLC_Diagram.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### An inefficient way to store data...\n",
    "\n",
    "##### A single table with records of customer purchases at an outdoor sports store.\n",
    "\n",
    "![Inefficient Table](img/Inefficient_Table.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Relational Database Management Systems\n",
    "\n",
    " - A RDBMS is a type of database where **data is stored in multiple related tables.**\n",
    " - The tables are related through **primary** and **foreign keys**.\n",
    " - The same information as shown before in an RDBMS:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Primary Keys\n",
    "\n",
    " - Every table in a RDBMS has a **primary key**  that uniquely identifies that row\n",
    " - Each entry must have a primary key, and primary keys cannot repeat within a table\n",
    " - Primary keys are usually integers, often [GUIDs or UUIDs](https://www.guidgenerator.com/online-guid-generator.aspx), but can take other forms\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Foreign Keys and Table Relationships\n",
    "\n",
    " - A **foreign key** is a column that uniquely identifies a column in another table\n",
    " - Often, a foreign key in one table is a primary key in another table\n",
    " - We can use foreign keys to join tables\n",
    " \n",
    "  ![Foreign Key Diagram](img/Foreign_Key_Diagram.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entity Relationship Diagram (ERD)\n",
    "\n",
    "An Entity Relationship Diagram (ERD) represents how each forien key and primary key connects the tables. When using real production data, these diagrams can take up many pages.\n",
    "\n",
    "![ERD](img/ERD_Diagram.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Database Normalization\n",
    "- technique of organizing the data in the database)\n",
    "    - reduce redundancy of data\n",
    "    - make sure data dependancies make some logical sense\n",
    "    \n",
    "    \n",
    "##### Store each piece of information in exactly one place\n",
    " - Details about a user (address, age) are only stored once (in a users table)\n",
    " - Any other table (eg. purchases) where this data might be relevant, only references the user_id\n",
    " \n",
    "![RDBMS](img/RDBMS_Diagram.png)\n",
    "\n",
    "##### Why is this a good thing?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normal Forms (levels of normalization) \n",
    "\n",
    "Normalization is explained through *Normal forms*\n",
    "\n",
    " - 1st Normal Form: a single cell holds only a single value\n",
    "     \n",
    "<!-- Example: Employee information stored in one table and an employee has two phone numbers... \n",
    "Update the table to allow a different row of name, salary... for each phone number they have now each cell would have one value only\n",
    " -->\n",
    "\n",
    " - 2nd Normal Form: no dependencies on part of a key\n",
    " \n",
    "<!--  Example: Employee ID and Department ID make up the primary key for a table... and lets say office location is a column which only depends on department id... no good... lets fix it by splitting into two tables... -->\n",
    " \n",
    " \n",
    " - 3rd Normal Form: no transitive dependencies\n",
    " \n",
    "<!--  Example: Employee id determines which deparment id they are in and the department id determines the department name. Therefore we have a transitive relationship... If we split the data where any non-primary attribute is not dependent on another non-primary attribute we will improve the referential integrety of our db and elimiate duplication of data -->\n",
    "\n",
    "\n",
    "![normal_forms](img/normal_forms.png)\n",
    "\n",
    "**There are more leveles but we just need to start with the first three"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Why Not Normalize?\n",
    "\n",
    "Sometimes databases are not fully normalized.\n",
    "\n",
    " - Data structure not known/may change\n",
    " - Writing a schema/converting data is hard\n",
    " - Simple queries are important\n",
    " - Data will not be changed/integrity not important\n",
    " - Storage is cheap\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![DLBC2](img/DBLC_Diagram2.jpg)\n",
    "#### Data Science in the DBLC\n",
    "\n",
    " - Data Science Operations: querying, aggregating\n",
    " - Data Science Implementation: identifying, cleaning, pushing external data sources inside a RDBMS\n",
    " - Data Science Design: recommendations on the model, specs on operations\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a table with a schema\n",
    "\n",
    "![Create Table](img/create_table.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inserting values into a table\n",
    "\n",
    "![insert into table](img/Insert_into_table.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SQL Queries for table creation / maintenance\n",
    "\n",
    "Creating a table from query:\n",
    "```sql\n",
    "CREATE [TEMPORARY] TABLE table AS <SQL query>;\n",
    "```\n",
    "Inserting records in a table:\n",
    "```sql\n",
    "INSERT INTO table [(c1,c2,c3,…)] VALUES (v1,v2,v3,…);\n",
    "```\n",
    "Updating records:\n",
    "```sql\n",
    "UPDATE table SET c1=v1,c2=v2,… WHERE cX=vX;\n",
    "```\n",
    "Delete records:\n",
    "```sql\n",
    "DELETE FROM table WHERE cX=vX;\n",
    "```\n",
    "Change model (add, drop, modify columns):\n",
    "```sql\n",
    "ALTER TABLE table [DROP/ADD/ALTER] column [datatype];\n",
    "```\n",
    "Delete a table:\n",
    "```sql\n",
    "DROP TABLE table;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Order of Evaluation of a SQL SELECT Statement\n",
    "\n",
    "1. FROM + JOIN: first the product of all tables is formed\n",
    "2. WHERE: the where clause filters rows that do not meet the search condition\n",
    "3. GROUP BY + (COUNT, SUM, etc): the rows are grouped using the columns in the group by clause and the aggregation functions are applied on the grouping\n",
    "4. HAVING: like the WHERE clause, but can be applied after aggregation\n",
    "5. SELECT: the targeted list of columns are evaluated and returned\n",
    "6. DISTINCT: duplicate rows are eliminated\n",
    "7. ORDER BY: the resulting rows are sorted\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Order of Evaluation of a SQL SELECT Statement\n",
    "\n",
    "![Order of Evaluation](img/Order_of_Evaluation.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Excecution Plan\n",
    "\n",
    "When troubleshooting a query, you may want to figure out what your query is in fact doing. Most SQL systems have their own internal query optomiser, so if the query you write is not in the most efficient form, the sql system will optomize it. Sometimes still your query will fail. You can use the Execution plan to troubleshoot this.\n",
    "\n",
    "![Exec](img/exec_plan.png)\n",
    "\n",
    "If you are concerned about running too large a query, you can run your execution plan prior to running the query. Running to large of a query may be hard to accomplish using the datasets you find online, but can be a real concern when working with real world data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lecture Objectives\n",
    "\n",
    "#### Part 1 SQL with python (psycopg2):\n",
    "\n",
    "- Connect to a database from within a python program and run queries\n",
    "- Understand psycopg2's cursors and commits\n",
    "- Generate dynamic queries\n",
    "\n",
    "#### Part 2 RDBMS the why and how:\n",
    "\n",
    " - Why an RDBMS?\n",
    " - The database lifecycle (and where the data scientist fits!)\n",
    " - Primary keys, foriegn keys, and the ERD\n",
    " - Creating and maintaining tables\n",
    " - Order of Evaluation of a SQL SELECT Statement\n",
    " - Transactions\n",
    " - SQL Execution Plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
