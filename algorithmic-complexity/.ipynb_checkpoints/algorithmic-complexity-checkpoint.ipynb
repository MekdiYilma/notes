{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computational Complexity and Big-O Notation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the goals of computer programming is writing code that runs quickly. It's not the most important goal -- generally it's much more important to write maintainable, readable code -- but in some cases performance is critical. The first step to writing fast code is understanding how to measure it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Success Criteria\n",
    "Today I will be successful if I can...\n",
    "\n",
    "1. Discuss big(O) notation\n",
    "2. Describe the differences between bubble sort and insert sorting algorithms\n",
    "3. Use Big O notaion to determine the complexities of various functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motivation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to be able to describe the efficiency of a particular algorithm.\n",
    "\n",
    "We can't just talk about how long it takes to run a function. Different computers and languages work differently and run at different speeds. There's really no easy way to talk about how long a program will take without running it, and that will only help us in certain circumstances.\n",
    "\n",
    "What we can do is estimate how the computer time will grow for larger and larger input.\n",
    "\n",
    "It turns out this is really important. When writing production code we mostly test code on small inputs, usually smaller than we'd see in the real world. If the code – even a small part of the code is highly dependent on the size of the input, it might run fine initially but fall apart in a crisis. Large software systems undergo *scalability testing*, but it's best to find these problems earlier.\n",
    "\n",
    "In data science we frequently deal with *big data*. In such cases it's particularly important that the computation time (and memory usage) doesn't grow much faster than the size of the input data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Big-O Notation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Big-O nation is a mathematical notation to descrbie **limiting behavior** of a function when the argument tends towards a particular value or infinity. \n",
    "\n",
    "For now we'll imagine a program with an input of length $n$ and we want to understand how it behaves.\n",
    "\n",
    "#### Let's first look at O(1) complexity. \n",
    "- Only a single step required to complete the task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def appending(x, lst):\n",
    "    lst.append(x)         #O(1)\n",
    "    return lst[-1] == x   #O(1)\n",
    "\n",
    "lst = [x for x in range(10)]\n",
    "x = 8\n",
    "\n",
    "appending(x, lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As our list grows. Our comparisons remain the same, in this case, no comparison needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = [x for x in range(100)]\n",
    "x = 8\n",
    "\n",
    "appending(x, lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is unreasonable to imagine our algorithms consistantly have the same run time and comparisons irrelevant to the input length so let's look at a more common complexity. \n",
    "\n",
    "#### O(N) complexity. \n",
    "- The number of of steps required is directly related to n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(10)\n",
    "\n",
    "def check_lst_element(x, lst):\n",
    "    for idx, val in enumerate(lst):                \n",
    "        if val == x:                                 \n",
    "            return print(f'{x}: at index {idx}')   \n",
    "    return print(f\"Nope, {x} is not in list\")      \n",
    "        \n",
    "        \n",
    "lst = np.random.randint(0, 10, 10)\n",
    "x = 8\n",
    "check_lst_element(x, lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the list grows, the comparison between the value and the list grow as well. Especially considering the worst case scenario. (having the value at the very end of the list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "lst = np.random.randint(0, 100, 100)\n",
    "x = 8\n",
    "check_lst_element(x, lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### O$\\mathcal (log n)$ complexity (logarithmic)\n",
    "- The number of steps it takes to accomplish the task are decreased by some factor with each step. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here we see the function move through each value in the range of n and print them all... \n",
    "# as the N increases, the print out will increase linearlly\n",
    "def some_function(n):\n",
    "    val = 0\n",
    "    while val < n:\n",
    "        val += 1\n",
    "        print(val)\n",
    "\n",
    "some_function(8) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here we see the function start to sift through each value, but in each loop, the run time is cut in half\n",
    "# as the N increases, the print out will increase logarithmically: this is better than O(N)\n",
    "def some_function(val):\n",
    "    index = 1\n",
    "    while index < val:\n",
    "        index *=2\n",
    "        print(index)\n",
    "\n",
    "some_function(100) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### O$\\mathcal (n^2)$ complexity. \n",
    "- The number of steps it takes to accomplish a task is square of n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_pairs(lst):\n",
    "    for x in lst:           \n",
    "        for y in lst:           \n",
    "            if x == y:          \n",
    "                print(x,y)      \n",
    "            \n",
    "lst = np.arange(0, 10)\n",
    "print_pairs(lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are comparing each item in lst with every other item in list.\n",
    "\n",
    "As our list grows. Our comparisons increase in a quadratic fashion. So 10 elements will have 100 comparisons... 100 elements in a list will have 10,000 comparisons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Another note on O$\\mathcal (n^2)$ complexity. \n",
    "\n",
    "Complexity works a bit different if we are comparing two different lists. The \"n\" in our big O notation is refering to the length of our list N. \n",
    "\n",
    "What is our runtime complexity of the following function?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_pairs(lst1, lst2):\n",
    "    for n in lst1:           \n",
    "        for m in lst2:           \n",
    "            if n == m:          \n",
    "                print(n,m)      \n",
    "            \n",
    "lst1 = np.arange(0, 10)\n",
    "lst2 = np.random.randint(0,10,5)\n",
    "print_pairs(lst1, lst2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are comparing each item in lst1 with every item in list 2.\n",
    "\n",
    "As both of our lists grow, our comparisons increase in a quadratic fashion. However, if one list is grows and the other stays stagnant we need a way to discuss that complexity. Instead of saying we have a complexity of  O$\\mathcal (n^2)$, we say we have a complexity of  O$\\mathcal (nm)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Big-O nation is a mathematical notation to descrbie **limiting behavior** of a function when the argument tends towards a particular value or infinity. \n",
    "\n",
    "For now we'll imagine a program with an input of length $n$ and we want to understand how it behaves.\n",
    "\n",
    "We have a couple important concepts that we want to express mathematically. \n",
    "\n",
    "- First, we don't really care about constant factors. So if a program takes $n$ seconds to complete, or $2n$, or $100n$, we want to treat those as being all the same ($n$ is rather large), but if it takes $n^2$ seconds, that's something else.\n",
    "\n",
    "- Second, we're interested in **asymptotic** behavior, how a system behaves as $n\\to\\infty$. For example, if the one part of the program takes $n$ seconds to run, and the other part takes $0.00001n^2$ seconds, eventually, for large enough $n$, the second part will dominate and the whole thing will be proportional to $n^2$. \n",
    "\n",
    "The way we express this is called \"big-O notation.\" For example, if a program will take $5 + 5n^{} + 2n^2$ seconds to run, it's said to be $\\mathcal O(n^2)$. If it always takes the same amount of time independent of $n$ it's $\\mathcal O(1)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In summation: \n",
    "\n",
    " * constants don't matter (note that $M$ term), and\n",
    " * only the fastest-growing term matters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computational Complexity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So how do we consider that in code? Consider the function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_sum(lst):\n",
    "    '''Sum the numbers in a sequence'''\n",
    "    result = 0\n",
    "    for x in lst:\n",
    "        result += x\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question: How long should this take as a function of the size of the input list?\n",
    "\n",
    "Let's test it. We're drawing a lot of numbers from a random distribution, so we'll create the distribution object first. Note that `%%timeit` measures the time to run the entire cell, *excluding* the first line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = stats.norm(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit lst = dist.rvs(100)\n",
    "my_sum(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit lst = dist.rvs(200)\n",
    "my_sum(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit lst = dist.rvs(400)\n",
    "my_sum(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit lst = dist.rvs(800)\n",
    "my_sum(lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So it looks as if the time to run it is proportional to the size of the input, each double of n doubles our time. a.k.a., it's an $\\mathcal O(n)$ algorithm. Here's how we'd figure that out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_sum(lst):\n",
    "    result = 0         # O(1)\n",
    "    for x in lst:      # O(n)\n",
    "        result += x    # O(1)\n",
    "    return result      # O(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How about this? Note we're iterating over the indices rather than the elements, but that shouldn't make a difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxdiff(lst):\n",
    "    '''find the maximum absolute difference of elements in lst\n",
    "    Example: \n",
    "    lst = [2,4,6,5,9]\n",
    "    ---> 7'''\n",
    "    result = 0\n",
    "    for i in range(len(lst)):\n",
    "        for j in range(len(lst)):\n",
    "            if abs(lst[i] - lst[j]) > result:\n",
    "                result = abs(lst[i] - lst[j])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How long should this take as a function of $n$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit lst = dist.rvs(100)\n",
    "maxdiff(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit lst = dist.rvs(200)\n",
    "maxdiff(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit lst = dist.rvs(400)\n",
    "maxdiff(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit lst = dist.rvs(800)\n",
    "maxdiff(lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So here each doubling of our input increases our time by 2^2 if we tripled our input length it would increase our time by 3^2. \n",
    "\n",
    "But wait! Our function is considering every pair of numbers twice, but since we're taking the absolute value of the differences we don't need to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxdiff(lst):\n",
    "    '''find the maximum absolute difference of elements in lst'''\n",
    "    result = 0\n",
    "    for i in range(len(lst)):\n",
    "        for j in range(i): # instead of looking at that list again...\n",
    "            print(i)\n",
    "            print(f'j: {j}')\n",
    "            if abs(lst[i] - lst[j]) > result:\n",
    "                result = abs(lst[i] - lst[j])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit lst = dist.rvs(100)\n",
    "maxdiff(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit lst = dist.rvs(200)\n",
    "maxdiff(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit lst = dist.rvs(400)\n",
    "maxdiff(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit lst = dist.rvs(800)\n",
    "maxdiff(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "125/29, 29.6/7.7, 7.7/1.97"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So even though it takes a shorter amount of time we still see that the use of our double four loop compares each value in the list to the previous values getting rid of the repeates from the original function. The complexity is still quadratic because we are considering magnitude and ignoring constants. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first case we're looking at the square of n:\n",
    "$$\\sum_{i=0}^{n-1} n = n^2$$\n",
    "\n",
    "In the second case we have\n",
    "$$\\sum_{i=0}^{n-1} i = \\tfrac12{n(n-1)} \\approx \\tfrac12{n^2}$$\n",
    "\n",
    "To look at it graphically, for the first case for $n=6$ we have\n",
    "\n",
    "`\n",
    ". . . . . .\n",
    ". . . . . .\n",
    ". . . . . .\n",
    ". . . . . .\n",
    ". . . . . .\n",
    ". . . . . .\n",
    "`\n",
    "\n",
    "While for the second case we have\n",
    "\n",
    "`\n",
    ".\n",
    ". .\n",
    ". . .\n",
    ". . . .\n",
    ". . . . .\n",
    "`\n",
    "\n",
    "We're only looking at half of the square here, so we save a factor of two, but **the computational complexity is the same**. These sorts of double loops are pretty common.\n",
    "\n",
    "It's pretty common the obvious solution to a problem is $\\mathcal O(n^2)$ but there's a faster solution. Could we do better here?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Built-in functions - lookup in a list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to figure out the overall computational complexity of our code, we need to know the complexity for built-in functions.\n",
    "\n",
    "What's the computational complexity of checking if something is in a list?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit lst = dist.rvs(10**3); x = dist.rvs()\n",
    "x in lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit lst = dist.rvs(10**4); x = dist.rvs()\n",
    "x in lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit lst = dist.rvs(10**5); x = dist.rvs()\n",
    "x in lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit lst = dist.rvs(10**6); x = dist.rvs()\n",
    "x in lst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we wrote it as a function it would look a bit like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_in_list(x, lst):\n",
    "    for element in list:  # O(n)\n",
    "        if x == element:  # O(1)\n",
    "            return True\n",
    "    return False          # O(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best, Worst, and Average Cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We assumed above that we have to look through the entire list to find something, but what if the element we're looking for is the first one? That's what's called the **best case**; if that's true here we can solve the problem in $O(1)$ time.\n",
    "\n",
    "Knowing the best case isn't that useful, because it doesn't happen very often, and it's not safe to rely on it. A better approach is to look at the **average case**, for a typical situation. For the average case above (assuming the element is in the list) we'll have to look at half of the elements before we find it. We generally care about the average case, because we'll be running our algorithm many times and the average performance matters.\n",
    "\n",
    "We also need to consider the **worst case**, for a couple reasons. \n",
    "- First, even though the worst case might be rare, we still may need to handle it without catastrophic failure. If the worst-case performance will cause our server to crash, we have a problem.\n",
    "\n",
    "- Second, the worst-case scenario, though rare on random data, might be common on real-world situations. [Quicksort](https://en.wikipedia.org/wiki/Quicksort#Algorithm) (on the common sorting algorithms) is $\\mathcal O(n \\log n)$ complexity on average but $\\mathcal O(n^2)$ in the worst case. That might seem ok, except the worst case occurs when the list is already sorted – a fairly common situation. To avoid this it's common to shuffle the list before sorting; or randomely pick the pivot (i.e., not start from either left- or right-most item in the array)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lookup in a sorted list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often we can perform operations faster if the data is organized in a particular way to start with. Suppose we knew that the list was sorted in increasing order. How could we look for something in the list without checking every single element?\n",
    "\n",
    "Let's write a function to do this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_in_sorted_list(x, lst):\n",
    "    lower = 0\n",
    "    upper = len(lst) - 1\n",
    "    while lower - 1  < upper:\n",
    "        current = (lower + upper) // 2\n",
    "        if x == lst[current]:\n",
    "            return True\n",
    "        elif x < lst[current]:\n",
    "            upper = current - 1\n",
    "        else:\n",
    "            lower = current + 1\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit lst = sorted(dist.rvs(10**2)); x = dist.rvs()\n",
    "is_in_sorted_list(x, lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit lst = sorted(dist.rvs(10**3)); x = dist.rvs()\n",
    "is_in_sorted_list(x, lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit lst = sorted(dist.rvs(10**4)); x = dist.rvs()\n",
    "is_in_sorted_list(x, lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit lst = sorted(dist.rvs(10**5)); x = dist.rvs()\n",
    "is_in_sorted_list(x, lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit lst = sorted(dist.rvs(10**6)); x = dist.rvs()\n",
    "is_in_sorted_list(x, lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "4.1/3.46 , 3.46/2.94, 2.94/1.99, 1.99/1.18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks as if it's taking longer to for the larger lists, maybe growing linearly as the lists grow geometrically. That's a $\\mathcal O(\\log n)$ growth.\n",
    "\n",
    "In general, log terms in computational complexity occur when you repeatedly divide the data. Think of the log as (roughly) the number of times you divide a number by two before you reach one. In the above case, that's the number of times we execute the loop, and the part inside is so this is $\\mathcal O(1)$, so the overall complexity is $\\mathcal O(\\log n)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now you do\n",
    "\n",
    "What are the time complexities of the following functions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(n):\n",
    "    i = 0\n",
    "    while i < n:\n",
    "        j = 0\n",
    "        while j < n:\n",
    "            print(str(i) + \", \" + str(j))\n",
    "            j += 1\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(n):\n",
    "    i = 1\n",
    "    while i < n:\n",
    "        i *= 2\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(n):\n",
    "        print(\"My name is Inigo Montoya\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
