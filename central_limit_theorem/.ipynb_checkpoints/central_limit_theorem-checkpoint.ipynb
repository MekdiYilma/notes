{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start with some quick review questions\n",
    "\n",
    "1. The bias of a coin is 0.8 in favor of Heads, what is the probability of flipping fewer than 4 heads out of 10 flips of the coin?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'P(k < 4): 0.0008643583999999986'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "p = 0.8\n",
    "n = 10\n",
    "k = 4\n",
    "\n",
    "f'P(k < 4): {stats.binom(n=10, p=0.8).cdf(k-1)}'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Using the parameters above, create a simulation using scipy.stats to flip this coin 10 times and view the results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Describe a sampling distribution? (maybe give an example if that is easier)\n",
    "4. How would you set up a bootstrapped sample?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Central Limit Theorem\n",
    "\n",
    "## Success Criteria\n",
    "By the end of class I will be successful if I can...\n",
    "\n",
    "1. Explain the central limit theorem in general terms\n",
    "2. Express with confidence information about the normal distribution\n",
    "3. Compute the standard error of a sample metric\n",
    "4. Compute a confidence interval of a sample without bootstrapping\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### As discussed earlier, there are many different types of distributions which emerge from various real-world situations\n",
    "\n",
    "#### The Normal, Gaussian or Bell Curve is perhaps the best known, and many distributions bear a passing resemblence to the normal curve, *however* most distributions are not the Normal distribution\n",
    "\n",
    "#### The Normal curve has been well studied and is relatively easy to calculate, so it would be nice if all random variables could be represented by the normal curve\n",
    "\n",
    "#### The central limit theorem gives us a way to transform non-normal distirbutions into normal distributions (under certain circumstances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Central Limit Theorem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Normal (Gaussian) Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **normal** or **gaussian** distribution has a hallowed place in statistical folklore, mostly due to the **central limit theorem** that we'll study shortly.\n",
    "\n",
    "Carl Freidrich Gauss derived it when he was asked by an astronomer to help him locate a new planet (that he had lost).  Gauss started by modeling astronomical measurement errors and proceeded to derive it. [source](https://www.math.utah.edu/~kenkel/normaldistributiontalk.pdf)\n",
    "\n",
    "The traditional notation for a normal random variable is $Z$ (instead of $X$, used for pretty much any other random variable).\n",
    "\n",
    "A normal random variable $Z$ has the cumulative distribution function\n",
    "\n",
    "$$ \\Phi (t) = \\frac{1}{\\sqrt{2 \\sigma^2 \\pi}} \\int_{- \\infty}^t e^{ - \\frac{(x - \\mu)^2}{2 \\sigma^2} } dx $$\n",
    "\n",
    "The $\\Phi$ is, again, traditional notation for the cumulative distribution function of a normal random variable. \n",
    "\n",
    "By differentiating, we get the density function of a normal random variable\n",
    "\n",
    "$$ \\phi (t) = \\frac{1}{\\sqrt{2 \\sigma^2 \\pi}} e^{ - \\frac{(x - \\mu)^2}{2 \\sigma^2} } $$\n",
    "\n",
    "The integral for the CDF of the normal distribution does *not* have a closed form.  In practice, the only way to compute values of the distribution function of a normal random variable is numerically using a computer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters of the Normal Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The $\\mu$ (mean) and $\\sigma$ (standard deviation) are the parameters of the distribution.  \n",
    "\n",
    "# Changing $\\mu$ translates the distribution function to the right and left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams.update({'font.size': 12})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_dist = stats.norm(8, 10)\n",
    "norm_dist.interval(0.68)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_dists_varying_mean = [\n",
    "    stats.norm(mu, 1) for mu in [-2, -1, 0, 1, 2]\n",
    "]\n",
    "\n",
    "x = np.linspace(-4, 4, num=250)\n",
    "fig, axs = plt.subplots(5, 2, figsize=(10, 10))\n",
    "\n",
    "for col, func in zip([0,1],[lambda z:z.pdf(x), lambda z:z.cdf(x)]):\n",
    "\n",
    "    for i, ax in enumerate(axs[:,col].flatten()):\n",
    "        ax.plot(x, func(normal_dists_varying_mean[i]), linewidth=2)\n",
    "        if i ==0:\n",
    "            titles = ['PDF', 'CDF']\n",
    "            ax.set_title(f'{titles[col]}')\n",
    "        ax.set_ylim(-0.1, 1.1)\n",
    "        ax.set_xlim(-4, 4)\n",
    "        ax.axvline(normal_dists_varying_mean[i].mean())\n",
    "        for interval in normal_dists_varying_mean[i].interval(.68):\n",
    "            ax.axvline(interval, color = 'green')\n",
    "\n",
    "plt.tight_layout(pad=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Changing $\\sigma$ stretches and shrinks the distribution function horizontally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_dists_varying_sigma = [\n",
    "    stats.norm(0, sigma) for sigma in [0.25, 0.5, 1, 2, 4]\n",
    "]\n",
    "\n",
    "x = np.linspace(-4, 4, num=250)\n",
    "fig, axs = plt.subplots(5, 2, figsize=(10, 10))\n",
    "\n",
    "for col, func in zip([0,1],[lambda z:z.pdf(x), lambda z:z.cdf(x)]):\n",
    "\n",
    "    for i, ax in enumerate(axs[:,col].flatten()):\n",
    "        ax.plot(x, func(normal_dists_varying_sigma[i]), linewidth=2)\n",
    "        ax.set_ylim(-.1,1.1)\n",
    "        ax.axvline(normal_dists_varying_sigma[i].mean())\n",
    "        for interval in normal_dists_varying_sigma[i].interval(.68):\n",
    "            ax.axvline(interval, color = 'green', alpha = .5)\n",
    "\n",
    "plt.tight_layout(pad=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal = stats.norm(0, 1) # instantiates the object <- good practice\n",
    "\n",
    "x = np.linspace(-3, 3, num=251)\n",
    "fig, ax = plt.subplots(1, 2, figsize=(14, 4))\n",
    "\n",
    "ax[0].plot(x, normal.cdf(x), linewidth=2)\n",
    "ax[0].set_ylim(-0.1, 1.1)\n",
    "ax[0].set_title(\"Normal(0, 1) Cum. Distribution Function\")\n",
    "\n",
    "ax[1].plot(x, normal.pdf(x), linewidth=2)\n",
    "ax[1].set_ylim(-0.05, 0.5)\n",
    "ax[1].set_title(\"Normal(0, 1) Density Function\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Consider our normal Distribution above to answer the following: \n",
    " \n",
    "1. What is the probability that a random variable drawn from this distribution is exactly equal to 2? \n",
    "<!-- 0  -->\n",
    "2. What is the probability that a random variable drawn from this distribution is around 2? \n",
    "\n",
    "<!-- normal.pdf(2) = 0.054 -->\n",
    "\n",
    "3. What is the probability that a random variable drawn from this distribution is between 1 and 2?\n",
    "\n",
    "<!-- normal.cdf(2) - normal.cdf(1) = 0.134 -->\n",
    " \n",
    "4. What is the probability a random value drawn from this distribution is either between 1 and 2, or between -1 and -0.5?\n",
    "\n",
    "<!-- (normal.cdf(2) - normal.cdf(1)) + (normal.cdf(-0.5) - normal.cdf(-1)) = 0.286-->\n",
    "\n",
    "##### *Use cdf/pdf to get answers*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_samples = normal.rvs(2500) # drawing random samples\n",
    "\n",
    "x = np.linspace(-3, 3, num=251)\n",
    "fig, ax = plt.subplots(1, 2, figsize=(14, 4)) # 2 axes: 0, 1\n",
    "\n",
    "# axes 0\n",
    "ax[0].hist(normal_samples, bins=50, density=False)\n",
    "ax[0].set_xlim(-3, 3)\n",
    "#ax[0].set_ylim(-0.05, 0.5) #  use if density=True\n",
    "ax[0].set_title(\"Histogram of Samples from a Normal(0, 1)\")\n",
    "\n",
    "# axes 1\n",
    "ax[1].plot(x, normal.pdf(x), linewidth=2)\n",
    "ax[1].set_xlim(-3, 3)\n",
    "ax[1].set_ylim(-0.05, 0.5)\n",
    "ax[1].set_title(\"Normal(0, 1)) Density Function\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Central Limit Theorem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A primary application of the normal distribution is the central limit theorem.  Let's show why."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Distribution of the Sample Means\n",
    "\n",
    "Let's return to the distribution of a very popular statistic, the **distribution of the sample means**. Remember how we worked with these sample statistics during our bootstrapping conversation. \n",
    "\n",
    "Consider a fixed population, and for the moment, suppose we have the power to sample freely, as many data points as we wish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_dim_scatterplot(data, ax, jitter=0.2, **options):\n",
    "    if jitter:\n",
    "        jitter = np.random.uniform(-jitter, jitter, size=data.shape)\n",
    "    else:\n",
    "        jitter = np.repeat(0.0, len(data))\n",
    "    ax.scatter(data, jitter, **options)\n",
    "    ax.yaxis.set_ticklabels([])\n",
    "    ax.set_ylim([-1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(5, figsize=(16, 6), sharex=True)\n",
    "\n",
    "population = stats.expon(2)\n",
    "sample_sizes = [25, 50, 75, 100, 125]\n",
    "for sample_size, ax in zip(sample_sizes, axs.flatten()):\n",
    "    sample = population.rvs(sample_size)\n",
    "    one_dim_scatterplot(sample, ax, s=25, c=\"black\")\n",
    "    \n",
    "_ = fig.suptitle(\"Samples from a Very Non-Normal Population\", fontsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Suppose we fix a sample size, and repeatedly sample from the population with that fixed size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 50\n",
    "\n",
    "fig, axs = plt.subplots(10, figsize=(16, 10), sharex=True)\n",
    "\n",
    "for i, sample_size in enumerate(sample_sizes):\n",
    "    sample = population.rvs(sample_size)\n",
    "    one_dim_scatterplot(sample, axs[2*i], s=25, c=\"black\")\n",
    "    axs[2*i+1].hist(sample)\n",
    "    \n",
    "_ = fig.suptitle(\"Samples from a Very Non-Normal Population\", fontsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember, the **sampling distribution of the mean** is the distribution of the means computed from these *different samples*.\n",
    "\n",
    "Here, we've superimposed the sample means on each of our sample means.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(5, figsize=(16, 6), sharex=True)\n",
    "\n",
    "for sample_size, ax in zip(sample_sizes, axs.flatten()):\n",
    "    sample = population.rvs(sample_size)\n",
    "    one_dim_scatterplot(sample, ax, s=25, c=\"black\")\n",
    "    ax.scatter(sample.mean(), 0, color='red', s=100)\n",
    "    \n",
    "_ = fig.suptitle(\"Samples from a Very Non-Normal Population\", \n",
    "                 fontsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do that, let's repeatedly sample, compute the means of the samples, then plot the distribution of these means.\n",
    "\n",
    "Each of the red dots in the above visualization is counted **one time** in the histogram below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#n_samples is number of samples from populaton\n",
    "#n_summands is how many values are in each sample\n",
    "#sampler is our population to sample from\n",
    "\n",
    "def sample_from_repeated_sum(n_samples, n_summands, sampler):\n",
    "    \"\"\"Sample n_samples from the sum of n_summands iid copies of a random\n",
    "    varaible.\n",
    "    \"\"\"\n",
    "    samples = sampler.rvs(n_samples*n_summands).reshape(n_samples, n_summands)\n",
    "    return np.sum(samples, axis=1)\n",
    "\n",
    "def sample_means_from_population(n_samples, n_summands, sampler): \n",
    "    return (1.0/n_summands) * sample_from_repeated_sum(n_samples, n_summands, sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_means = sample_means_from_population(\n",
    "    n_samples=10000, n_summands=50, sampler=population)\n",
    "\n",
    "fig, ax = plt.subplots(1, figsize=(10, 4))\n",
    "_ = ax.hist(sample_means, bins=50, density=True, color=\"red\", alpha=0.5)\n",
    "_ = ax.set_title(\"Distributon of Sample Means (Sample Size = 50)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The averaging has greatly reduced the rightward skew of our original data distribution. \n",
    "\n",
    "### Our process has smothed out the original distribution and made it look symmetrical\n",
    "\n",
    "Let's overlay a normal distribution with the correct mean and variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_sample_means = np.mean(sample_means)\n",
    "variance_sample_means = np.var(sample_means)\n",
    "sample_means_model = stats.norm(mean_sample_means, \n",
    "                                np.sqrt(variance_sample_means))\n",
    "\n",
    "fig, ax = plt.subplots(1, figsize=(10, 4))\n",
    "ax.hist(sample_means, bins=50, density=True, color=\"red\", alpha=0.5,\n",
    "            label=\"Histogram of Sample Means\")\n",
    "x = np.linspace(1, 5, num=250)\n",
    "ax.plot(x, sample_means_model.pdf(x), linewidth=2, color=\"black\", \n",
    "        label=\"Normal PDF With Same Mean and Variance\")\n",
    "ax.set_title(\"Distributon of Sample Means (Size = 10000)\")\n",
    "ax.legend(loc='lower left');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yah, that looks pretty close."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Central Limit Theorem\n",
    "\n",
    "The **central limit theorem** asserts that as we take the mean of larger and larger samples, the distribution of sample means becomes more and more normal.\n",
    "\n",
    "Said differently, probabilistic statements about the mean of a large sample can be well approximated by assuming that the distribution of the sample means is a normal distribution with the correct mean and variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note:  The Central Limit Theorem does not say that \"as we take more and more samples, the distribution becomes normal.\"\n",
    "\n",
    "#### For the Central Limit Theorem to work, we have to do *something* to a our samples, such as take the mean or the sum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "population = stats.expon(2, scale = 2)\n",
    "samples = population.rvs([10000, 1000])\n",
    "sums = np.sum(samples, axis=1)\n",
    "\n",
    "plt.hist(sums, bins =100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# running 10,000 simulations, and mean is based on varying\n",
    "# size of sample\n",
    "size_of_sample = [1, 2, 5, 10, 25, 50, 100, 200, 500]\n",
    "\n",
    "fig, axs = plt.subplots(3, 3, figsize=(16, 12))\n",
    "\n",
    "for sample_size, ax in zip(size_of_sample, axs.flatten()):\n",
    "    sample_means = sample_means_from_population(\n",
    "        n_samples=10000, n_summands=sample_size, sampler=population)\n",
    "    variance_sample_means = np.var(sample_means)\n",
    "    sample_means_model = stats.norm(mean_sample_means, \n",
    "                                    np.sqrt(variance_sample_means))\n",
    "    ax.hist(sample_means, bins=100, density=True, color=\"red\", alpha=0.5)\n",
    "    t = np.linspace(min(sample_means), max(sample_means), num=250)\n",
    "    ax.plot(t, sample_means_model.pdf(t), color=\"black\")\n",
    "    _ = ax.set_title(\"Sample Size = {}\".format(sample_size), fontsize=16)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statement of the Central Limit Theorem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose $X_1, X_2, \\ldots$ are i.i.d. copies of a random varaiable with finite expectation and variance\n",
    "\n",
    "$$ E[X_1] = E[X_2] = \\cdots = \\mu $$\n",
    "$$ var[X_1] = var[X_2] = \\cdots = \\sigma^2 $$\n",
    "\n",
    "Then the distribution of sample means tends to a normal distribution with the appropriate mean and standard deviation:\n",
    "\n",
    "$$ \\frac{X_1 + X_2 + \\cdots + X_k}{k} \\rightarrow N \\left( \\mu, \\frac{\\sigma}{\\sqrt{k}} \\right) $$\n",
    "\n",
    "as $k \\rightarrow \\infty$.\n",
    "\n",
    "**Note:** The CLT also applies to a simple sum, though the mean and variance are different\n",
    "\n",
    "$$ X_1 + X_2 + \\cdots + X_k \\rightarrow N \\left( k \\mu, \\sqrt{k} \\sigma \\right) $$\n",
    "\n",
    "The type of convergence is the CLT is called [convergence in distribution](https://en.wikipedia.org/wiki/Convergence_of_random_variables#Convergence_in_distribution)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A couple of notes\n",
    "\n",
    "  - The stunning part of the central limit theorem is that it makes almost no assumptions about $X$.  $X$ can be anything, and it's sample means will always tend to be normal.\n",
    "  - The central limit theorem is a **miracle**, pure and simple.  There is no real *reason* it is true, it just is.  Consider it a gift of rare order in the universe, more like a fundamental law of physics than an intuitive mathematical fact.\n",
    "  - Here's an elevator pitch statement of the central limit theorem, good for job interviews: **The central limit theorem allows us to make probabilistic statements about the sample mean from any population using the normal distribution.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: The Binomial Distribution\n",
    "\n",
    "Consider a binomial distribution $Binom(n, p)$, which assigns probabilities to the number of heads shown in $n$ flips of a coin where the probability of seeing a head in a **single flip** is $p$.\n",
    "\n",
    "Consider a variable $X$ which is distributed as binomial\n",
    "\n",
    "$$ X \\sim Binom(n, p) $$\n",
    "\n",
    "and also a ton of variables representing **single coin flips**\n",
    "\n",
    "$$ X_1, X_2, \\ldots \\sim Binom(1, p) $$\n",
    "\n",
    "**Claim:** $X \\sim X_1 + X_2 + \\cdots + X_n$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The central limit theorem has an immediate consequence:  Binomial distributions with large $n$ tend to be approximately normal!\n",
    "\n",
    "$$ Binom(n, p) \\sim N(np, \\sqrt{n p (1 - p)} ) $$\n",
    "\n",
    "\n",
    "<!-- $npq$ or $np(1-p)$ is the variance of the binomial distribution and the standard deviation is the square root of the variance. \n",
    "\n",
    "$pq$ is the variance of the bernoulli distribution.  -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binomial = stats.binom(n = 1_000_000, p = 0.4)\n",
    "\n",
    "normal_approx = stats.norm(np.mean(binomial_sample), binomial.std())\n",
    "\n",
    "# binomial ~ normal_approx\n",
    "#VISUAL BELOW TO HELP SHOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binomial = stats.binom(n = 1_000_000, p = 0.4)\n",
    "binomial_sample = binomial.rvs(100_000)\n",
    "\n",
    "binomial_sample_mean = np.mean(binomial_sample)\n",
    "binomial_sample_variance = np.var(binomial_sample)\n",
    "normal_approx = stats.norm(\n",
    "    binomial_sample_mean, np.sqrt(binomial_sample_variance))\n",
    "\n",
    "fig, ax = plt.subplots(1, figsize=(10, 4))\n",
    "_ = ax.hist(binomial_sample, bins=100, density=True, color=\"red\", alpha=0.5)\n",
    "x = np.linspace(binomial.ppf(.001), binomial.ppf(.999), num=250)\n",
    "ax.plot(x, normal_approx.pdf(x), linewidth=3, color=\"black\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An immediate consequence: Binomial probabilities with large $n$ can be well approximated using the normal distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for understanding: Binomial Probabilities\n",
    "\n",
    "You flip a fair coin 10,000 times.  What is the probability that you flip heads between 5000 and 5100 times?\n",
    "\n",
    "* Work it out using the scipy.stats binomial distribution.  \n",
    "* Then work it out using the scipy.stats normal distribution.\n",
    "\n",
    "Do you get the same answer?\n",
    "\n",
    "<!--\n",
    "n = 10000\n",
    "p = 0.5\n",
    "coin_binom = stats.binom(n,p)\n",
    "prob_binom = coin_binom.cdf(5100) - coin_binom.cdf(4999)\n",
    "prob_binom.round(3) -->\n",
    "\n",
    "<!-- \n",
    "mu = n * p\n",
    "std = np.sqrt(n * p * (1 - p))\n",
    "coin_norm = stats.norm(mu, std)\n",
    "prob_norm = coin_norm.cdf(5100) - coin_norm.cdf(4999)\n",
    "prob_norm.round(3) \n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Another example if needed: \n",
    "\n",
    "There are fifty people waiting in line at the DMV an hour before closing time. At this point, no one else will be allowed in to add to the line. The time it takes to serve a person has a mean of five minutes and a standard deviation of three minutes. Five people can be served at a time. What is the probability that all fifty people can be served within the last hour of the day? \n",
    "\n",
    "\n",
    "\n",
    "Assume IID\n",
    "\n",
    "We are going to have some Random variables... the amount time it takes each person to be helped. \n",
    "\n",
    "$ X_i $ = minutes needed to serve the ith person \n",
    "$i$ has a range of 1 - 50\n",
    "\n",
    "$$ X_1 + X_2 + \\cdots + X_i $$ = Total minutes of service needed for all people to be served \n",
    "\n",
    "\n",
    "$$ X_1 + X_2 + \\cdots + X_i \\sim N(mean = 50*5, \\sqrt{n}*\\sigma ) $$\n",
    "\n",
    "\n",
    "```\n",
    "norm = stats.norm(50*5, 3*np.sqrt(50))\n",
    "\n",
    "# P(X <- 60 * 5) \n",
    "#minutes of service available\n",
    "norm.cdf(300)\n",
    "```\n",
    "\n",
    "As long as we know a mean and std of a potential situation we can determine using CLT that the normal distribution would approximately represent the sum of iid random variables. Therefore we can use Normal distribution to make some determinations.  -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Central Limit Theorem: The Point\n",
    "\n",
    "When we are concerned with a **sample mean**, the central limit theorem lets us derive the **actual distribution of the sample mean**.  This allows us to calculate probabilities about the sample mean.\n",
    "\n",
    "We are going to make good use of this when we design statistical hypothesis tests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: CLT Based Confidence Interval for the Sample Mean\n",
    "\n",
    "Consider our sample from a secret population, which we have used as a running example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = stats.norm(0.9, 1.0).rvs(100)\n",
    "\n",
    "fig, ax = plt.subplots(1, figsize=(16, 2))\n",
    "one_dim_scatterplot(data, ax, s=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here are the facts we have accumulated about this situation\n",
    "\n",
    "  - The sample mean is an approximation of the population mean: the expected value of the sample mean *is* the population mean.\n",
    "  - The sample mean is approximately normally distributed, the mean and variance of this normal distribution can be computed in terms of the population mean and variance, and the size of the sample.\n",
    "  \n",
    "Let's denote by \n",
    "  - $\\mu$ the population mean.\n",
    "  - $\\sigma^2$ the population variance.\n",
    "  - $\\bar x$ the **sample mean**.\n",
    "  \n",
    "Then we can summarize all this as\n",
    "\n",
    "$$ \\bar x \\sim N \\left( \\mu, \\frac{\\sigma}{\\sqrt{n}} \\right) $$  \n",
    "\n",
    "where $$ \\frac{\\sigma}{\\sqrt{n}} $$ is the effective standard deviation of the sampling distribution of the sample mean, commonly called the [standard error.](https://en.wikipedia.org/wiki/Standard_error)  \n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we subtract the population mean from both sides we get\n",
    "\n",
    "$$ \\bar x - \\mu \\sim N \\left( 0, \\frac{\\sigma}{\\sqrt{n}} \\right) $$\n",
    "\n",
    "Which allows us to make probabilistic statements about how far the sample mean is from the population mean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A **confidence interval** is the answer to a question like this\n",
    "\n",
    "> How far do I have to go to the left and the right of the sample mean so that 95% of the time (i.e. in 95% of possible samples) I will have enclosed the population mean?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $\\alpha$ denote the distance you move to the left and right of the sample mean when drawing your interval.  In notation, we are asking to find $\\alpha$ such that\n",
    "\n",
    "$$ P(\\bar x - \\alpha \\leq \\mu \\leq \\bar x + \\alpha) = 0.95 $$\n",
    "\n",
    "This is the same as asking for\n",
    "\n",
    "$$ P( - \\alpha \\leq \\mu - \\bar x \\leq \\alpha ) = 0.95 $$\n",
    "\n",
    "The thing in the middle here, $\\mu - \\bar x$, has a known distribution!\n",
    "\n",
    "$$ \\bar x - \\mu \\sim N \\left( 0, \\frac{\\sigma}{\\sqrt{n}} \\right) $$\n",
    "\n",
    "So, visually, we are looking for:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_mean = np.mean(data)\n",
    "sample_varaince = np.var(data)\n",
    "distribution_of_sample_minus_population_mean = stats.norm(0, np.sqrt(sample_varaince / len(data)))\n",
    "\n",
    "fig, ax = plt.subplots(1, figsize=(10, 4))\n",
    "x = np.linspace(-0.3, 0.3, num=250)\n",
    "pdf = distribution_of_sample_minus_population_mean.pdf(x)\n",
    "ax.plot(x, pdf, linewidth=3)\n",
    "\n",
    "# Shade under curve\n",
    "# Note: The 0.2 here is just for illustration, it does not correspond to\n",
    "#       any particular value of alpha.\n",
    "\n",
    "ax.set_xlim(-0.3, 0.3)\n",
    "ax.fill_between(x, pdf, 0, \n",
    "                where=( (-0.2 <= x) * (x <= 0.2) ), color=\"red\", alpha=0.2)\n",
    "ax.text(-0.04, 1.5, \"0.95\", fontsize=35, color=\"red\")\n",
    "ax.set_xticks([]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shaded region is the area under the density between $-\\alpha$ and $\\alpha$. We want the **shaded region** to account for $0.95$ of the total area.\n",
    "\n",
    "This means that each *half* of the shaded area to the *left and right* of zero should account for $0.475$ of the total area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, figsize=(10, 4))\n",
    "\n",
    "ax.plot(x, pdf, linewidth=3)\n",
    "\n",
    "# Shade under curve\n",
    "ax.set_xlim(-0.3, 0.3)\n",
    "ax.fill_between(x, pdf, 0, \n",
    "                where=( (-0.2 <= x) * (x <= 0.0) ), color=\"red\", alpha=0.2)\n",
    "ax.text(-0.15, 0.6, \"0.475\", fontsize=35, color=\"red\")\n",
    "ax.set_xticks([]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which means that the \"tail\" to the left of $\\alpha$ should account for $0.5 - 0.475 = 0.025$ of the total area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, figsize=(10, 4))\n",
    "\n",
    "ax.plot(x, pdf, linewidth=3)\n",
    "\n",
    "# Shade under curve\n",
    "ax.set_xlim(-0.3, 0.3)\n",
    "ax.fill_between(x, pdf, 0, \n",
    "                where=( (x <= -0.2) ), color=\"red\", alpha=0.2)\n",
    "ax.text(-0.18, 0.2, \"0.025\", fontsize=35, color=\"red\")\n",
    "ax.set_xticks([]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is **this kind of area that is computed by the distribution function**.\n",
    "\n",
    "So, if we denote by $F$ the **distribution function of** $ N \\left( 0, \\frac{\\sigma}{\\sqrt{n}} \\right) $, then we are after the value of $\\alpha$ satisfying\n",
    "\n",
    "$$ F(-\\alpha) = 0.025 $$\n",
    "\n",
    "Or $$F^{-1}(0.025) = -\\alpha$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, figsize=(10, 4))\n",
    "\n",
    "ax.plot(x, pdf, linewidth=3)\n",
    "\n",
    "# Shade under curve\n",
    "ax.set_xlim(-0.3, 0.3)\n",
    "ax.fill_between(x, pdf, 0, \n",
    "                where=( (x <= -0.2) ), color=\"red\", alpha=0.2)\n",
    "ax.text(-0.18, 0.2, \"0.025\", fontsize=35, color=\"red\")\n",
    "ax.axvline(x=-0.2, ymin=0.0, ymax=100, color=\"black\", \n",
    "           linestyle='--', alpha=0.5)\n",
    "ax.text(-0.2, -0.5, r\"$\\alpha$\", fontsize=16)\n",
    "_ = ax.set_xticks([]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **inverse of the distribution function** is often called the **percentile function**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = distribution_of_sample_minus_population_mean.ppf(0.025)\n",
    "print(\"Sample Mean: {:2.2}\".format(sample_mean))\n",
    "print(\"95% confidence interval for the population mean: [{:2.2}, {:2.2}]\".format(\n",
    "    sample_mean + alpha, sample_mean - alpha)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall our interpretation here\n",
    "\n",
    "> If we draw samples from the population and compute this confidence interval many, many times, then the computed interval should envelop the true population parameter approximately 95% of the time.\n",
    "\n",
    "In this case, I wrote the code to create the population, so I know the correct answer\n",
    "\n",
    "**The population mean is $0.1$.**\n",
    "\n",
    "So let's run a simulation and see if everything worked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_confidence_interval(data, confidence_width):\n",
    "    sample_mean = np.mean(data)\n",
    "    sample_varaince = np.var(data)\n",
    "    distribution_of_sample_minus_population_mean = stats.norm(0, np.sqrt(sample_varaince / len(data)))\n",
    "    alpha = distribution_of_sample_minus_population_mean.ppf(0.5 - \n",
    "                                                            (confidence_width / 2.0))\n",
    "    # Alpha is negative\n",
    "    return sample_mean + alpha, sample_mean - alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "population_mean_is_in_interval = []\n",
    "for i in range(1000):\n",
    "    new_data = stats.norm(0.1, 0.1).rvs(100)\n",
    "    left_endpoint, right_endpoint = compute_confidence_interval(new_data, 0.95)\n",
    "    population_mean_is_in_interval.append(left_endpoint <= 0.1 <= right_endpoint)\n",
    "    \n",
    "print(\"Proportion of confidence intervals containing the true parameter: {:2.2f}\".format(\n",
    "        np.mean(population_mean_is_in_interval)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which is what we would expect.\n",
    "\n",
    "To dive the point home, we can plot all of these confidence intervals along with the true parameter, and visually see which do and do not contain the parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, figsize=(16, 4))\n",
    "ax.plot([0, 100], [0.1, 0.1])\n",
    "\n",
    "for i in range(100):\n",
    "    new_data = stats.norm(0.1, 0.1).rvs(100)\n",
    "    sample_mean = new_data.mean()\n",
    "    left_endpoint, right_endpoint = compute_confidence_interval(new_data, 0.95)\n",
    "    color = \"grey\" if (left_endpoint <= 0.1 <= right_endpoint) else \"red\"\n",
    "    ax.plot([i, i], [left_endpoint, right_endpoint], color=color)\n",
    "    ax.scatter([i], [sample_mean], c=\"black\", s=20)\n",
    "    ax.set_xlim(-1, 100)\n",
    "    \n",
    "ax.set_title(\"Coverage of Confidence Intervals\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for Understanding: Confidence Interval\n",
    "[UCI's Machine Learning Repository](https://archive.ics.uci.edu/ml/index.php) has an [Activity Recognition from Chest Mounted Accelerometer](https://archive.ics.uci.edu/ml/datasets/Activity+Recognition+from+Single+Chest-Mounted+Accelerometer) dataset which recorded uncalibrated accelerations a person experienced while performing various activities at 52 Hz (52 measurements per second).  In the `data` folder there is a subset of this data, which is vertical (z) acceleration a person experiences during two activities: walkin and climbing stairs.\n",
    "\n",
    "What is the average vertical acceleration experienced by those walking, and by those climbing stairs?  For each, calculate the 95% confidence interval.\n",
    "\n",
    "Instead of using the ppf, you can use the [68-95-99.7 rule](https://en.wikipedia.org/wiki/68%E2%80%9395%E2%80%9399.7_rule) to approximate how many standard deviations away from the mean contain 95% of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps to help...\n",
    "1. Read in Data\n",
    "2. How many samples are you working with? store that as variable n.\n",
    "3. Find and store the means and stds of both our samples we are interested in. \n",
    "4. Use stds to determine our stadard error metric (This measures variability of a sample metric not individual data points)\n",
    "5. Compute 95% confidence Interval using 68-95-99.7 rule\n",
    "\n",
    "<!-- \n",
    "df = pd.read_csv('data/z_acceleration.csv')\n",
    "\n",
    "n = df.shape[0]\n",
    "\n",
    "walking_mean = df['walking'].mean()\n",
    "climbing_mean = df['climbing_stairs'].mean()\n",
    "\n",
    "walking_std = df['walking'].std()\n",
    "climbing_std = df['climbing_stairs'].std()\n",
    "\n",
    "walking_se = walking_std / np.sqrt(n)\n",
    "climbing_se = climbing_std / np.sqrt(n)\n",
    "\n",
    "walk_95_int = round(walking_mean - 2*walking_se, 2), round(walking_mean + 2*walking_se, 2)\n",
    "climbing_95_int = round(climbing_mean - 2*climbing_se, 2), round(climbing_mean + 2*climbing_se, 2)\n",
    "\n",
    "\n",
    "# We are 95% confident that the population mean lies within this margin of error. \n",
    "# More specifically if we were to take many samples, then 95% percent of the time the \n",
    "# the population mean would lie in this margin of error.\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
