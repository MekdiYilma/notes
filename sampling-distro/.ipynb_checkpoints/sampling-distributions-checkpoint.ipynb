{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "lst = np.arange(5)\n",
    "lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.choice(lst, size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampling Distributions\n",
    "\n",
    "**Success Criteria**\n",
    "\n",
    "Today I will be successful if I can ...\n",
    "\n",
    "1. Explain what a Random Variable is in Statistics\n",
    "2. Describe differences between CDF, PDF, and PMF\n",
    "1. Explain what is meant by i.i.d.\n",
    "2. Describe a sample statistic\n",
    "3. Explain a statistic distribution \n",
    "4. Detail what steps are required to bootstrap a sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Always make it pretty.\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Variables\n",
    "\n",
    "Recall that a random variable X is an object that can be used to generate numbers, in a way that variable makes up some probability distribution. \n",
    "\n",
    "Discrete: Distinct or separate values\n",
    "\n",
    "Continuous: Take on any value in an interval\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Lets say we have Random Variable X and it is equal to 1 if a coin flips heads and 0 if a coin flip results in tails. (is this discrete or continuous?)\n",
    "\n",
    "\n",
    "    Lets say we have Random Variable Y and it is equal to the mass of a random animal selected at the San Diego Zoo.  (is this discrete or continuous?)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some discrete distributions:\n",
    "\n",
    "What's the relationship between the pmf and cdf?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binomial = stats.binom(n=8, p=0.5)\n",
    "uniform = stats.randint(0,9)\n",
    "poisson = stats.poisson(2)\n",
    "\n",
    "def plot_dist_discrete(dist, name, ax):\n",
    "    ax[0].bar(np.arange(9), dist.pmf(np.arange(9)))\n",
    "    ax[0].set_title('pmf: {}'.format(name))\n",
    "    ax[1].bar(np.arange(9), dist.cdf(np.arange(9)))\n",
    "    ax[1].set_title('cdf: {}'.format(name))\n",
    "    ax[1].set_ylim(0, 1)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(3, 2, figsize=(12, 12))\n",
    "\n",
    "plot_dist_discrete(binomial, 'binomial', ax[0])\n",
    "plot_dist_discrete(uniform, 'uniform', ax[1])\n",
    "plot_dist_discrete(poisson, 'poisson', ax[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some continuous distributions:\n",
    "\n",
    "What's the relationsihp between the pdf and the cdf?\n",
    "\n",
    "What is the absolute likelihood of getting a value of e.g. 0.03 on one of these distributions?\n",
    "\n",
    "What is the *relative* likelihood of getting a particular value?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniform = stats.uniform(-10, 20)\n",
    "normal = stats.norm(0, 5)\n",
    "cauchy = stats.cauchy(0, 5)\n",
    "exponential = stats.expon(0, 5)\n",
    "\n",
    "def plot_dist_continuous(dist, name, ax):\n",
    "    x = np.linspace(-20, 20, 100)\n",
    "    ax[0].plot(x, dist.pdf(x))\n",
    "    ax[0].set_title('pdf: {}'.format(name))\n",
    "    ax[1].plot(x, dist.cdf(x))\n",
    "    ax[1].set_title('cdf: {}'.format(name))\n",
    "    ax[1].set_ylim(0, 1)\n",
    "    if dist == exponential:\n",
    "        ax[0].set_xlim(0, 20)        \n",
    "        ax[1].set_xlim(0, 20)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(3, 2, figsize=(12, 12))\n",
    "\n",
    "plot_dist_continuous(uniform, 'uniform', ax[0])\n",
    "plot_dist_continuous(normal, 'normal', ax[1])\n",
    "plot_dist_continuous(exponential, 'exponential', ax[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identically Distributed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If two random variables have the *same* distribution function, we say they are *identically distributed*, and we denote this relationship\n",
    "\n",
    "$$ X \\sim Y $$\n",
    "\n",
    "In practice this means **any probabilistic statements we make about $X$ and $Y$ have the same answer**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rv_1 = stats.norm(0,10)\n",
    "rv_2 = stats.norm(0,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Observation from first random variable: {}\".format(rv_1.rvs()))\n",
    "print(\"Observation from first random variable: {}\".format(rv_2.rvs()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.sort(rv_1.rvs(100)), np.linspace(0, 1, 100), alpha = 0.7)\n",
    "plt.plot(np.sort(rv_2.rvs(100)), np.linspace(0, 1, 100), color = 'blue', alpha = 0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampling Theory\n",
    "\n",
    "In this section we will take another path towards understanding samples taken from an unknown population.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling Distributions of Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What is a sampling distribution? \n",
    "\n",
    "Imagine we are interested in a parameter of some population, like the average height of women in Data Science. We don't have access to the population so I start with getting a sample of 20 Data Scientist. \n",
    "\n",
    "    Population Parameter: Average Height\n",
    "\n",
    "So I have gathered numerous samples, each size 20.f I can gather means from my various samples of information coming in. \n",
    "\n",
    "    Sample Statistics: Average Height of each random sample\n",
    "\n",
    "Now the question is, what is the distribution of all of the sample statistics, this is known as our Sampling Disribution?\n",
    "\n",
    "    Sampling Distribution: Distribution of Sample Statistics \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A more complex and in depth view:\n",
    "\n",
    "\n",
    "This Distribution helps us mathematically model a simple random sample. For example, each of the following can be modeled as taking an i.i.d. (independent and identically distributed) random sample from a population:\n",
    "\n",
    "  - A random survey of humans is an i.i.d sample of all humans of interest to the survey designers.\n",
    "  - A dataset of all the quotes received for an insurance product is an i.i.d sample of all possible customers of the insurance company.\n",
    "  - Driving around a city and turning a random direction at each intersection is an i.i.d sample of all possible paths driven through the city (as long as you start in a random place).\n",
    "  \n",
    "When we have such a situation, we will adopt a slight change in perspective that will make our mathematics work out more easily:\n",
    "\n",
    "**We consider each individual data point drawn from our population as the outcome from its own random variable.**\n",
    "\n",
    "So, under this model, a i.i.d sample can be thought of as a **sequence of random variables that are independent and identically distributed**\n",
    "\n",
    "$$ X_1, X_2, X_3, \\ldots, X_n $$\n",
    "\n",
    "When we actually **physically take** the sample, i.e. **collect data**, we get datapoints $x_1, x_2, \\ldots, x_n$, each one drawn from the corresponding random varaible $X_k$.\n",
    "  \n",
    "A **statistic** is a function of a random sample $T(X_1, X_2, ..., X_n)$.  I.e., something we can compute once we have a random sample.  Drawing different random samples will result in different values of the statistic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples of Statistics\n",
    "\n",
    "Here are a couple simple and common statistics.  To illustrate, we've drawn 20 samples from a normal distribution and recorded the value of the statistic.\n",
    "\n",
    "The **sample mean** is a statistic defined by $\\frac{1}{n} \\sum_i X_i$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "normal = stats.norm(64.5, 2.5)\n",
    "\n",
    "fig, axs = plt.subplots(3, 2, figsize=(16, 6), sharex=True)\n",
    "\n",
    "\n",
    "\n",
    "for ax in axs.flatten():\n",
    "    samp = normal.rvs(20)\n",
    "    ax.scatter(samp, np.repeat(0, 20))\n",
    "    mean = np.mean(samp)\n",
    "\n",
    "    ax.scatter([mean], 0, c=\"black\", s=80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **sample maximum** is defined by $\\max (X_1, X_2, \\ldots, X_n)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "normal = stats.norm(64.5, 2.5)\n",
    "\n",
    "fig, axs = plt.subplots(3, 2, figsize=(16, 6), sharex=True)\n",
    "\n",
    "for ax in axs.flatten():\n",
    "    samp = normal.rvs(20)\n",
    "    ax.scatter(samp, np.repeat(0, 20))\n",
    "    M = np.max(samp)\n",
    "    ax.scatter([M], 0, c=\"black\", s=80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** What is another sample statistic that is commonly encountered?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Explain in your own words why sample statistics are random varaibles.  Give an example of an interesting probability involving a sample statistic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Main Question In Sampling Theory\n",
    "\n",
    "#### How do we **quantify** the amount of variation of a sample statistic?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To quantify the amount of variation of a statistic, we would really like a process like this:\n",
    "\n",
    "  - Draw some number of independent and identically distributed data from the population $X$, i.e. a sample.\n",
    "  - Compute the statistic using the sample you drew.\n",
    "  - Record the value of the statistic just computed in a database.\n",
    "  - Do it again, and again, and again, until the sun burns out.\n",
    "  \n",
    "After this process is complete, we have many examples of our statistic, each computed from a different random sample from our variable.\n",
    "\n",
    "The distribution of *the statistic* that arises from this process is called the **sampling distribution of the statistic**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Sample Means from A Normal Variable\n",
    "\n",
    "Recall our sample means from the previous example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "normal = stats.norm(64.5, 2.5)\n",
    "\n",
    "fig, axs = plt.subplots(3, 2, figsize=(16, 6), sharex=True)\n",
    "\n",
    "\n",
    "means = []\n",
    "for ax in axs.flatten():\n",
    "    samp = normal.rvs(20)\n",
    "    ax.scatter(samp, np.repeat(0, 20))\n",
    "    mean = np.mean(samp)\n",
    "    means.append(mean)\n",
    "    ax.scatter([mean], 0, c=\"black\", s=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution of the *black points* is the **sampling distribution of the mean**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(16, 2))\n",
    "ax.scatter(means, np.repeat(0, 6), c='black', s=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we superimpose a sample from the original distribution, it's very clear that the spread of the sampling distribution is much smaller than that of the original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "fig, ax = plt.subplots(1, 1, figsize=(16, 2))\n",
    "ax.scatter(normal.rvs(20), np.repeat(0, 20))\n",
    "ax.scatter(means, np.repeat(0, 6), c='black', s=50);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two questions present themselves:\n",
    "\n",
    "  - What is the average value of the statistic?\n",
    "  - How much does the statistic vary around its average value?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_dim_scatterplot(data, ax, jitter=0.2, **options):\n",
    "    if jitter:\n",
    "        jitter = np.random.uniform(-jitter, jitter, size=data.shape)\n",
    "    else:\n",
    "        jitter = np.repeat(0.0, len(data))\n",
    "    ax.scatter(data, jitter, **options)\n",
    "    ax.yaxis.set_ticklabels([])\n",
    "    ax.set_ylim([-1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "normal = stats.norm(64.5, 2.5)\n",
    "\n",
    "means = []\n",
    "for ax in range(20):\n",
    "    samp = normal.rvs(20)\n",
    "    mean = np.mean(samp)\n",
    "    means.append(mean)\n",
    " \n",
    "    \n",
    "fig, ax = plt.subplots(1, 1, figsize=(16, 2))\n",
    "ax.scatter(normal.rvs(20), np.repeat(0, 20))\n",
    "one_dim_scatterplot(np.array(means), ax, jitter=0.2, c='black', s=50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Bootstrap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we will see later next week, the central limit theorem is nice, it is a central result in mathematical statistics, and there is no other result in the subjects with the definitive nature of the CLT.\n",
    "\n",
    "On the other hand, it has a huge drawback: **it only works for a single statistic, the sample mean!**  It would be nice to have a general procedure that will let us estimate the varaince (or the entire distribution) of **any sample statisic**.\n",
    "\n",
    "### Bootstrap Samples\n",
    "\n",
    "We generally have one fixed dataset, which we view as a single sample from the population.  **The population is the object that interests us, and the sample is the lens through which we get to view it.**\n",
    "\n",
    "The idea behind the bootstrap is that the **empirical distribution** of the sample should be our **best approximation** to the distribution of the population the sample is drawn from.  We can illistrate this by comapring the emperical distribution functions of samples to the actual population distribution functions:\n",
    "\n",
    "<!-- emperical distribution: Best estimate of population distribution aka -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pdf not acutally used in this notebook... here just in case you want to play with pdf\n",
    "def superimpose_pdf_of_fit_model(data, model, ax, x_lower=-3, x_upper=3):\n",
    "    x = np.linspace(x_lower, x_upper, num=250)\n",
    "    _ = ax.hist(data, bins=25, normed=True, color=\"black\", alpha=0.4)\n",
    "    ax.plot(x, model.pdf(x), linewidth=3)\n",
    "    \n",
    "def emperical_distribution(x, data):\n",
    "    weight = 1.0 / len(data)\n",
    "    count = np.zeros(shape=len(x))\n",
    "    for datum in data:\n",
    "        count = count + np.array(x >= datum)\n",
    "    return weight * count\n",
    "    \n",
    "    \n",
    "def superimpose_cdf_of_fit_model(data, model, ax, x_lower=-3, x_upper=3):\n",
    "    x = np.linspace(x_lower, x_upper, num=250)\n",
    "    ax.plot(x, emperical_distribution(x, data), linewidth=2, label='Sample')\n",
    "    ax.plot(x, model.cdf(x), linewidth=2, label='Distribution')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "population = stats.norm(0.9, 0.6)\n",
    "\n",
    "fig, axs = plt.subplots(1, 4, figsize=(16, 3))\n",
    "\n",
    "for ax in axs.flatten():\n",
    "    sample = population.rvs(50)\n",
    "    superimpose_cdf_of_fit_model(sample, population, ax)\n",
    "    ax.legend()\n",
    "fig.suptitle(\"Population vs. Sample CDFs\", fontsize=16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "population = stats.uniform(-2, 2.5)\n",
    "\n",
    "fig, axs = plt.subplots(1, 4, figsize=(16, 3))\n",
    "\n",
    "for ax in axs.flatten():\n",
    "    sample = population.rvs(100)\n",
    "    superimpose_cdf_of_fit_model(sample, population, ax)\n",
    "    ax.legend()\n",
    "fig.suptitle(\"Population vs. Sample CDFs\", fontsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that  **since we cannot repeatedly sample from the population, our next best bet is to sample from the sample itself**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bootstrap: The Big Idea\n",
    "\n",
    "We want to do this:\n",
    "\n",
    "> Estimate the variance of a sample statistic by repeatedly sampling from the population, computing the sample means of these samples, and then computing the variance of the multiple sample means.\n",
    "\n",
    "But we **can't**, because we can **only sample from the population one time**.\n",
    "\n",
    "Instead, we repeatedly sample from our **best approximation to the population distribution**, which is given by the **empirical density function of the sample**.\n",
    "\n",
    "That is, instead we do\n",
    "\n",
    "> Estimate the variance of the sample means by repeatedly sampling from *a distribution approximating the population distribution*, computing the sample means of these samples, and then computing the variance of the multiple sample means."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition\n",
    "\n",
    "A **bootstrap sample** from a dataset is a sample taken with replacement from that dataset whose size is the size of the dataset itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = stats.norm(0.1, 1.0).rvs(100)\n",
    "\n",
    "def text_in_blank_plot(text, ax):\n",
    "    _ = ax.text(0.5, 0.5, text, \n",
    "                horizontalalignment='center',\n",
    "                verticalalignment='center',\n",
    "                fontsize=22)\n",
    "    ax.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16, 6))\n",
    "\n",
    "ax = plt.subplot2grid((6, 3), (0, 0), colspan=2)\n",
    "ax.set_xlim(-3, 3)\n",
    "one_dim_scatterplot(data, ax, s=25)\n",
    "ax = plt.subplot2grid((6, 3), (0, 2), colspan=1)\n",
    "text_in_blank_plot(\"Original Sample\", ax)\n",
    "\n",
    "for i in range(0, 5):\n",
    "    bootstrap = np.random.choice(data, size=len(data), replace=True)\n",
    "    ax = plt.subplot2grid((6, 3), (i + 1, 0), colspan=2)\n",
    "    ax.set_xlim(-3, 3)\n",
    "    one_dim_scatterplot(bootstrap, ax, s=25, c=\"black\")\n",
    "    ax = plt.subplot2grid((6, 3), (i + 1, 2), colspan=1)\n",
    "    text_in_blank_plot(\"Bootstrap Sample\", ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each bootstrap sample has it's **own** sample median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16, 6))\n",
    "\n",
    "ax = plt.subplot2grid((6, 3), (0, 0), colspan=2)\n",
    "ax.set_xlim(-3, 3)\n",
    "one_dim_scatterplot(data, ax, s=25)\n",
    "ax = plt.subplot2grid((6, 3), (0, 2), colspan=1)\n",
    "text_in_blank_plot(\"Original Sample\", ax)\n",
    "\n",
    "for i in range(0, 5):\n",
    "    bootstrap_sample = np.random.choice(data, size=len(data), replace=True)\n",
    "    ax = plt.subplot2grid((6, 3), (i + 1, 0), colspan=2)\n",
    "    ax.set_xlim(-3, 3)\n",
    "    one_dim_scatterplot(bootstrap_sample, ax, c=\"black\", s=25)\n",
    "    sample_mean = np.median(bootstrap_sample)\n",
    "    ax.scatter([sample_mean], 0, c=\"red\", s=50)\n",
    "    ax = plt.subplot2grid((6, 3), (i + 1, 2), colspan=1)\n",
    "    text_in_blank_plot(\"Bootstrap Sample\", ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sample means taken from repeated bootstrap samples are then an approximation to the **distribution of the sample medians**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_sample_medians(data, n_bootstrap_samples=10000):\n",
    "    bootstrap_sample_medians = []\n",
    "    for i in range(n_bootstrap_samples):\n",
    "        bootstrap_sample = np.random.choice(data, size=len(data), replace=True)\n",
    "        bootstrap_sample_medians.append(np.median(bootstrap_sample))\n",
    "    return bootstrap_sample_medians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrap_medians = bootstrap_sample_medians(data)\n",
    "\n",
    "fig, ax = plt.subplots(1, figsize=(10, 4))\n",
    "_ = ax.hist(data, bins=25, density=True, color=\"black\", alpha=0.4,\n",
    "            label=\"Sample Data\")\n",
    "_ = ax.hist(bootstrap_medians, bins=25, density=True, color=\"red\", alpha=0.75,\n",
    "            label=\"Bootstrap Sample medians\")\n",
    "ax.legend()\n",
    "_ = ax.set_title(\"Bootstrap Sample medians (10000 samples)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use the bootstrap distribution of the sample median to estimate statistics like the variance of the sample median. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variance_of_sample = np.var(data)\n",
    "varaince_of_bootstrap_medians = np.var(bootstrap_medians)\n",
    "\n",
    "print(\"Variance of Sample: {:2.2f}\".format(variance_of_sample))\n",
    "print(\"Variance of Sample medians: {:2.2f}\".format(varaince_of_bootstrap_medians))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confidence Intervals: Capturing Population Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall our statement from earlier\n",
    "\n",
    "> Our general interest is in the **population**, the **sample** is just the lens we get to view it through.\n",
    "\n",
    "We have shown that **sample statistics are generally good approximations of properties of the population**, and we have also discovered **methods for approximating the distribution of sample statistics**  such as bootstrapping.\n",
    "\n",
    "Together these allow us to address a final question\n",
    "\n",
    "> How good of an approximation of a population parameter is a sample statistic?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Bootstrap Confidence Interval for the Standard Deviation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above example relied on the central limit theorem to provide the sampling distribution of the statistic, which is only possible for very specific sample statistics.\n",
    "\n",
    "Consider estimating a confidence interval of the median of a population.  In this case, the central limit theorem does not allow us to derive a mathematical form of the sampling distribution, instead we can proceed by using bootstrap sampling.\n",
    "\n",
    "Here is the bootstrap procedure for computing a confidence interval for a median\n",
    "\n",
    "  - Draw many bootstrap samples from your main sample, and for each:\n",
    "    - Compute the sample statistic (using the bootstrap sample)\n",
    "  - Gather together all the sample statistics of the various bootstrap samples into a list.\n",
    "  \n",
    "The resulting list can be considered as a sample from the sampling distribution of the statistic.\n",
    "\n",
    "  - Compute the 95% confidence interval by finding the 0.025 and 0.975 percentiles of the resulting list of sample statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrap_sample_std = []\n",
    "for i in range(10000):\n",
    "    bootstrap = np.random.choice(data, size=len(data), replace=True)\n",
    "    bootstrap_std = np.std(bootstrap)\n",
    "    bootstrap_sample_std.append(bootstrap_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code creates an approximation the the sampling distribution of the statistic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, figsize=(10, 4))\n",
    "_ = ax.hist(bootstrap_sample_std, bins=100, density=True, color=\"black\", alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get a confidence interval by computing the 0.025 and 0.975 percentiles of the resulting sampling distribution approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_endpoint = np.percentile(bootstrap_sample_std, 2.5)\n",
    "right_endpoint = np.percentile(bootstrap_sample_std, 97.5)\n",
    "\n",
    "print(\"Sample median: {:2.2f}\".format(np.std(data)))\n",
    "print(\"Bootstrap Confidence Interval for Population median: [{:2.2f}, {:2.2f}]\".format(\n",
    "    left_endpoint, right_endpoint))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, figsize=(10, 4))\n",
    "_ = ax.hist(bootstrap_sample_std, bins=100, density=True, color=\"black\", alpha=0.5)\n",
    "ax.axvline(left_endpoint)\n",
    "ax.axvline(right_endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Why is this confidence interval not symmetric?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bootstrap: The Point\n",
    "\n",
    "The Bootstrap is a tool to **quantify the variation in a statistical estimate**.  It can be used in almost **any** situation.\n",
    "\n",
    "The bootstrap is a giant point in favor of the massive amount of computation all of us has at our disposal in modern day.  Before the computer age, the practice of statistics was tedious and mathematical.  Now we can estimate things earlier generaitions would **never have dreamed of** by simply putting to work some carefully engeneered slabs of silicon.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: \n",
    "\n",
    "A recent Rasmussen poll polled 2500 likely voters. It found support for Joe Biden at 49%, and Trump at 46%  with a margin of error of 2 points.\n",
    "A Quippiniac poll polled 1426 likely voters. It found support for Joe Biden at 51% and Donald Trump at 41% with a margin of error of 2.6 points.\n",
    "\n",
    "What are the sample means? What are the population means? What are the margins of error? Can we use bootstrapping here? What is a likely voter anyway?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
