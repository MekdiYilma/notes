{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "monetary-cover",
   "metadata": {},
   "source": [
    "cost function for the following functions:\n",
    "\n",
    "Ordinary Least Squares: mean squared error/RMSE, r^2 or adjusted r^2, mean absolute error <br>\n",
    "Linear regression (L1 regularization) Lasso: RSS + lambda (sum of beta^2)<br>\n",
    "Linear regression (L2 regularization) Ridge: RSS + lambda (sum of /beta/)<br>\n",
    "Linear regression using Elastic net: RSS + lambda ((1-alpha / 2) sum of beta^2 + alpha sum of beta^2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aerial-brunei",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "sensitive-simpson",
   "metadata": {},
   "source": [
    "root note  - the first node for split; arrow comes out of the node but no arrow is point to it\n",
    "parent node/internal node - test a predictor value and not the final node; have arrows pointed to it and it has arrows points out of it\n",
    "leaf node -  assigns classifications/the final node; arrows coming into it, but no arrows coming out of it\n",
    "\n",
    "Process:\n",
    "For each feature, calculates information gain based on gini/enthropy impurity for all possible splits \n",
    "Makes a decision based on the highest information gain,\n",
    "If node has a lower score than the leaf node, no need for split consideration or otherwise (if splitting results lowers impurity), the process repeats again.\n",
    "\n",
    "\n",
    "1. Calculate the Gini impurity scores.<br>\n",
    "2. If the node itself has the lowest score, then there is no point in separating the patients anymore and it becomes a leaf node.<br>\n",
    "3. If separating the data results in improvement then pick the separation with the lowest impurity value.<br>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "For discrete features all of its possible values are evaluated, resulting in N calculated metrics for each of the variables, being N the number of possible value for each categorical value. e.g, class vs no class\n",
    "\n",
    "For continuous features the mean of each two consecutive values (ordered from lowest to highest) of the training data are used as possible thresholds. Impurity is calculated for each of the threshold, and the one with the lowest is set as the threshold to split on eg < threshold or >= threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solid-guidance",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "becoming-video",
   "metadata": {},
   "source": [
    "target: predict the female gold medal winner (high jump olympics)\n",
    "features: jumper_height, jumper_weight, best_jump_height,  fastest_100m_time\n",
    "\n",
    "\n",
    "Used decision-tree and model does well in training, but poor on test\n",
    "model performs ok during CV\n",
    "\n",
    "We have an overfit model meaning it has high variance and it is so specific.\n",
    "One method to reduce variance is to use bagging e.g, Random forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adolescent-grave",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "sacred-canada",
   "metadata": {},
   "source": [
    "Random Forest Randomness\n",
    "1. The dataset for each tree is generated with bootstrapping method (samples generated with replacement)\n",
    "2. As we create a decision tree with the bootstrap dataset, features are randomly selected from a subspace at each step of the split without replacement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recognized-silly",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "suspended-toronto",
   "metadata": {},
   "source": [
    "Bagging has bootstrapping and aggregation component to it and therefore can handle overfitting, reducing variance, and working with independent classifiers. RF is ensemble; it combines many weaker individual trees and form a stronger model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "micro-national",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "literary-pizza",
   "metadata": {},
   "source": [
    "Bagging - simple ensemble technique of bootstrapping the training data and building randomly selected features for trees, and then aggregating trees to form a single model.\n",
    ">> reduce variance\n",
    "\n",
    "Boosting - ensemble technique, where predictors are made independently, but sequentially. Each tree is grown using info from the prior tree.\n",
    ">> reduce bias and variance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smooth-commitment",
   "metadata": {},
   "source": [
    "The data that each tree in the ensemble is built on.\n",
    "> independently classifiers vs sequential classifiers\n",
    "\n",
    "How the quality of a split on a given feature and its value is evaluated.\n",
    "> low variance  vs low bias\n",
    "\n",
    "The general depth of each tree.\n",
    "?\n",
    "\n",
    "The bias-variance trade-off associated with each tree in the ensemble.\n",
    "> low variance  vs low bias\n",
    "\n",
    "How the ensemble can achieve a low-bias, low-variance model.\n",
    "> low variance  vs low bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "friendly-coverage",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fiscal-oregon",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "figured-springer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sum_to_target(nums, target):\n",
    "    '''\n",
    "    Given an array of integers and a target integer, return \n",
    "    indices of the two numbers in the array that sum to equal \n",
    "    the target.\n",
    "\n",
    "    You may assume that each input would have exactly one solution,  \n",
    "    and you may not use an element at the same index more than once.\n",
    "    \n",
    "    Return the indices in ascending order.   \n",
    "    For full points your solution should have a runtime of O(N). \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    nums: list\n",
    "    target: int\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "    \n",
    "    Input: nums = [3,2,4], target = 6\n",
    "    Output: [1,2]\n",
    "    '''\n",
    "    for i, n1 in enumerate(nums):\n",
    "        for j, n2 in enumerate(nums):\n",
    "            if i!=j and n1+n2 == target:\n",
    "                return [i,j]\n",
    "    return None\n",
    "\n",
    "sum_to_target([3,2,4], 6)               \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "otherwise-artist",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_node(X, y, col, split_val):\n",
    "    '''Split a feature matrix X and the target array y \n",
    "    into \"left\" and \"right\" arrays determined by splitting \n",
    "    on \"split_val\" in col of the X matrix.\n",
    "    \n",
    "    The \"left\" matrices of X and y contain the rows corresponding \n",
    "    to values in col <= split value, while the \"right\" matrices \n",
    "    contain the rows where col > split value.  Return the four arrays \n",
    "    separately (see example below).\n",
    "\n",
    "    You can assume that all columns in X are continuous values.  \n",
    "    col is an integer (0 indexed) that indicates which column of X \n",
    "    to use to split the X and y arrays.\n",
    "\n",
    "    Return empty arrays for the left or right arrays if no values \n",
    "    are returned.\n",
    "\n",
    "    FOR FULL POINTS DON'T USE LOOPS OR LIST COMPREHENSIONS.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X: NumPy array\n",
    "    y: NumPy array  \n",
    "    col: int\n",
    "    split_val: float\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    NumPy array, NumPy array, NumPy array, NumPy array\n",
    "\n",
    "    >>>X = np.array([[ 5.5,  2.4,  3.7],\n",
    "                     [ 5.5,  2.3,  3.8],\n",
    "                     [ 6.1,  3.0,  4.9],\n",
    "                     [ 5.2,  3.5,  1.5],\n",
    "                     [ 5.7,  2.6,  3.5]])\n",
    "\n",
    "    >>>y = np.array([1, 1, 2, 0, 1])\n",
    "\n",
    "    >>>X_left, y_left, X_right, y_right = split_node(X, y, 1, 2.6)\n",
    "\n",
    "    >>>X_left\n",
    "    array([[5.5, 2.4, 3.7],\n",
    "           [5.5, 2.3, 3.8],\n",
    "           [5.7, 2.6, 3.5]])\n",
    "\n",
    "    >>>y_left\n",
    "    array([1, 1, 1])\n",
    "    '''\n",
    "    mask = X[:,col] <= split_val\n",
    "    X_left, y_left, X_right, y_right = X[mask], y[mask], X[~mask], y[~mask]\n",
    "    return X_left, y_left, X_right, y_right\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "critical-wyoming",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array([[ 5.5,  2.4,  3.7],\n",
    "                     [ 5.5,  2.3,  3.8],\n",
    "                     [ 6.1,  3.0,  4.9],\n",
    "                     [ 5.2,  3.5,  1.5],\n",
    "                     [ 5.7,  2.6,  3.5]])\n",
    "mask = X[:,1] <= 2.6\n",
    "y = np.array([1, 1, 2, 0, 1])\n",
    "X[~idx]\n",
    "y[~idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "further-singer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True, False, False,  True])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "mexican-replication",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[5.5, 2.4, 3.7],\n",
       "        [5.5, 2.3, 3.8],\n",
       "        [5.7, 2.6, 3.5]]),\n",
       " array([1, 1, 1]),\n",
       " array([[6.1, 3. , 4.9],\n",
       "        [5.2, 3.5, 1.5]]),\n",
       " array([2, 0]))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_node(X, y, 1, 2.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "incorporated-segment",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_entropy(arr):\n",
    "    '''Return the Shannon entropy of a NumPy array containing only\n",
    "    two classes (integers 0 and 1).\n",
    "\n",
    "    You can assume that the array will always contain one or more values.\n",
    "    Do not assume that all classes are present in arr\n",
    "    \n",
    "    FOR FULL POINTS DO NOT USE AN IMPORTED ENTROPY FUNCTION\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    arr: NumPy array\n",
    "        Elements of of arr are binary (0 or 1)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "    '''\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "coupled-water",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = [0,1,2,0,0,2]\n",
    "\n",
    "for i in arr:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "excess-kinase",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_shannon_entropy(dna_sequence):\n",
    "    m = len(dna_sequence)\n",
    "    bases = collections.Counter([tmp_base for tmp_base in dna_sequence])\n",
    "\n",
    "    shannon_entropy_value = 0\n",
    "    for base in bases:\n",
    "        # number of residues\n",
    "        n_i = bases[base]\n",
    "        # n_i (# residues type i) / M (# residues in column)\n",
    "        p_i = n_i / float(m)\n",
    "        entropy_i = p_i * (math.log(p_i, 2))\n",
    "        shannon_entropy_value += entropy_i\n",
    "\n",
    "    return shannon_entropy_value * -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "complicated-workshop",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 3\n",
      "1 1\n",
      "2 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.4591479170272446"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import collections\n",
    "import math\n",
    "def estimate_shannon_entropy(arr):\n",
    "    m = len(arr)\n",
    "    count_d = collections.Counter(arr)\n",
    "\n",
    "    shannon_entropy_value = 0\n",
    "    \n",
    "    for k, v in count_d.items():\n",
    "        p_i = v / float(m)\n",
    "        entropy_i = p_i * (math.log(p_i, 2))\n",
    "        shannon_entropy_value += entropy_i\n",
    "\n",
    "    return shannon_entropy_value * -1\n",
    "\n",
    "estimate_shannon_entropy(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "raising-acceptance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 3, 1: 1, 2: 2})"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collections.Counter(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "useful-syracuse",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_series(start, length, index):\n",
    "    '''Create a pandas Series of length \"length\" with index \"index\"\n",
    "    and with elements that are sequential integers starting from \"start\".\n",
    "    You may assume the length of index will be \"length\".\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    start, length: int, int\n",
    "    index: list\n",
    "        Index of length \"length\"\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Pandas Series\n",
    "\n",
    "    >>>print(make_series(5, 3, ['a', 'b', 'c']))\n",
    "    a    5\n",
    "    b    6\n",
    "    c    7\n",
    "    dtype: int64\n",
    "    '''\n",
    "    return pd.Series(np.arange(start,start+length), index=index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "australian-discharge",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    5\n",
       "b    6\n",
       "c    7\n",
       "dtype: int64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(np.arange(5,5+3), index=['a', 'b', 'c'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "dressed-vinyl",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2\n",
      "1 3\n",
      "2 4\n"
     ]
    }
   ],
   "source": [
    "nums = [2,3,4]\n",
    "target = 6\n",
    "for i, n1 in enumerate(nums):\n",
    "#         for j, n2 in enumerate(nums):\n",
    "#             if i!=j and n1+n2 == target:\n",
    "#                 return [i,j]\n",
    "    print(i, n1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advised-luxembourg",
   "metadata": {},
   "source": [
    "```SELECT Neighborhood\n",
    "FROM rent\n",
    "WHERE City = 'San Francisco'\n",
    "AND State = 'CA'\n",
    "AND med_2014 IS NOT NULL\n",
    "AND med_2011 IS NOT NULL\n",
    "ORDER BY (med_2014 - med_2011)/med_2011 * 100.0 DESC\n",
    "LIMIT 5;```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "literary-bradley",
   "metadata": {},
   "source": [
    "SELECT r.Neighborhood, r.med_2014, b.med_2014\n",
    "FROM rent AS r\n",
    "JOIN buy AS b\n",
    "ON r.City = b.City\n",
    "WHERE r.City = 'San Francisco'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "opening-supplement",
   "metadata": {},
   "outputs": [],
   "source": [
    "Parent_Node = np.array([6, 5, 8, 8, 5, 4, 2, 4, 4])\n",
    "Left_Child_Node = np.array([6, 5, 8, 8])\n",
    "Right_Child_Node = np.array([5, 4, 2, 4, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "bacterial-tenant",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30.888888888888882"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum((Parent_Node - np.mean(Parent_Node))**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "dental-runner",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.75"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum((Left_Child_Node - np.mean(Left_Child_Node))**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "driving-chile",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.8"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum((Right_Child_Node - np.mean(Right_Child_Node))**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "relative-performer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "184.0"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_Node = np.array([156,167,160,170,172])\n",
    "sum((test_Node - np.mean(test_Node))**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mounted-tracker",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
